<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>やっていく</title>
  
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="http://ktrmnm.github.io/blog/"/>
  <updated>2020-03-22T11:21:07.296Z</updated>
  <id>http://ktrmnm.github.io/blog/</id>
  
  <author>
    <name>Kentaro MINAMI</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>(勉強メモ) Information bottleneck (1)</title>
    <link href="http://ktrmnm.github.io/blog/2020/03/22/20200322-information-bottleneck/"/>
    <id>http://ktrmnm.github.io/blog/2020/03/22/20200322-information-bottleneck/</id>
    <published>2020-03-22T06:59:07.000Z</published>
    <updated>2020-03-22T11:21:07.296Z</updated>
    
    <content type="html"><![CDATA[<p>Information bottleneck関係の個人的勉強メモです。</p><p>ブログでは、書くことの心理障壁を下げるために以前よりも勉強内容を小出しにしていくことを考えており、今日の目標は以下の元論文の主張をまとめておくことです。</p><ul><li>Tishby, Pereira, and Bialek (2000). The information bottleneck method. <a href="https://arxiv.org/abs/physics/0004057" target="_blank" rel="noopener">(URL)</a></li></ul><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Information bottleneck法 (Tishby et al. 2000) とは、<a href="https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory" target="_blank" rel="noopener">レート歪み理論</a> を一般化した概念である。レート歪み理論は非可逆圧縮の達成限界についての理論で、符号の空間のサイズ (レート) と復号時のエラー (歪み) の間のトレードオフを記述したものである。具体的に、このトレードオフは、「レート歪み関数」という、相互情報量をともなう最適化問題の最適値によって書ける。レート歪み関数の定義には、復号時のエラーを定義するための損失関数 (歪み関数) を指定する必要があるが、実用上は適切な損失関数を選ぶことが難しいことがある。Information bottleneck法では、$X$ に対する損失関数は陽に指定せず、その代わりに、符号のサイズは小さくしつつ別の信号 $Y$ に関係する情報を最大限保つという目的関数を考えることで、「$X$ の中の $Y$ に関係する情報」を抽出する問題を定式化する。例えば、$X$ を入力として $Y$ を予測する機械学習の問題があるとき、$Y$ の予測のために必要な情報はなるべく失わずに、最小限の大きさの特徴量 $\hat{X}$ を抽出したいというような状況が考えられるが、それを情報理論 (レート歪み理論) 的に解釈して定式化したのがinformation bottleneckであるというイメージ。</p><p>レート歪み理論の歪み (distortion) は「ひずみ」と読みます。</p><h1 id="Information-bottleneckの基礎"><a href="#Information-bottleneckの基礎" class="headerlink" title="Information bottleneckの基礎"></a>Information bottleneckの基礎</h1><h2 id="レート歪み理論"><a href="#レート歪み理論" class="headerlink" title="レート歪み理論"></a>レート歪み理論</h2><p>確率変数 $X$ を有限集合に値をとる符号に圧縮したい。$X$ の分布 $p(x)$ は既知とする。エンコーダーとデコーダーは確率的でもよいとし、まず (i) エンコーダーによって $X$ を $Z$ に符号化し、次に (ii) デコーダーによって $Z$ を $\hat{X}$ に復号化するプロセスを、まとめて条件付き分布 $p(\hat{X} \mid X)$ で表現するものとする。このプロセスの良さをはかるために、損失関数 $d$ を使って</p><p>$$<br>    D = \mathbb{E} [d(X, \hat{X})]<br>$$</p><p>によって損失を定義する。</p><p>$Z$ が値をとる空間のcardinalityの対数を $R$ と書き、レートと呼ぶ。原理的には、$R$ を増やすと信号 $X$ を無限に細かく離散化できるので、歪み $D$ は小さくなるはずである。逆に、$R$ を減らすと、表現力の低い符号によって $X$ の挙動を説明しなければならなくなるので、$D$ は大きくなる。したがって $R$ と $D$ にはトレードオフがあるが、このトレードオフの意味で最適なフロンティアがどこにあるか知りたい。$D &gt; 0$ を与えたときに、可能な限り最も短い $R$ を $R(D)$ と書く (これをレート歪み関数という)。</p><p>レート歪み理論によると、$R(D)$ は次の最適化問題の最適値に等しい。</p><p>$$<br>    \min_{p(\hat{x} \mid x)} I(X, \hat{X})<br>    \text{ s.t. } \mathbb{E} [d(X, \hat{X})] \leq D<br>    \tag{1}<br>$$</p><p>つまり、歪みが $D$ 以下に抑えられるようなエンコーダー/デコーダー対 $p(\hat{x} \mid x)$ のなかで、$X$ と $\hat{X}$ の相互情報量の最小値が、ぎりぎり達成可能な符号のサイズに対応している。</p><p>たまたま最近Cover and Thomasの輪読会をやったので、証明はその本で読んだ。$R \geq I(X, \hat{X})$ のようなことは不等式評価ですぐにわかるのだけど、達成可能性のほうは具体的なエンコーダー/デコーダーを作らなければならず、ちょっと込み入っているように感じた。他の方法はないのかと思って2冊目も確認したけど、だいたい同じ証明だった。</p><ul><li>Cover and Thomas. <a href="https://www.amazon.co.jp/dp/0471241954/ref=cm_sw_r_tw_dp_U_x_2hZDEb19PR3PV" target="_blank" rel="noopener">Elements of Information Theory</a> のChapter 10</li><li>Han. <a href="https://www.amazon.co.jp/Information-Spectrum-Information-Stochastic-Modelling-Probability/dp/3642078125" target="_blank" rel="noopener">Information-Spectrum Methods in Information Theory</a> のTheorem 5.2.1</li></ul><h2 id="レート歪み関数の計算"><a href="#レート歪み関数の計算" class="headerlink" title="レート歪み関数の計算"></a>レート歪み関数の計算</h2><p>現実には (1) の最適化問題の解や最適値をclosed formで計算するのは難しいので、数値計算のアルゴリズムが提案されている。ここでは、<a href="https://arxiv.org/abs/physics/0004057" target="_blank" rel="noopener">Tishby et al. (2000)</a> で紹介されているBlahut–Arimoto (BA) アルゴリズムについて書く。</p><p>(1) のLagrangianを書くと<br>$$<br>    I(X, \hat{X}) + \beta (\mathbb{E} [d(X, \hat{X})] - D)<br>    \tag{2}<br>$$<br>となる。$\beta$ はLagrange乗数である。</p><p>ここで、($D$ そのものではなく) $\beta &gt; 0$ を与えたときにLagrangianを最小化する問題を考えてみる。Lagrangianの $p(\hat{x} \mid x)$ に関する変分を考えると、停留条件は</p><p>$$<br>    p(\hat{x} \mid x) \propto p(\hat{x}) \exp( - \beta d(\hat{x}, x))<br>$$</p><p>のようになる。この停留条件の式に $p_t(\hat{x} \mid x)$ を再代入していくアルゴリズムを考えると、やがて不動点に収束することが示される。これがBAアルゴリズムと呼ばれている。</p><p>BAアルゴリズムは通信路容量を計算するのにも使われる。探したら以下のスライドがあった。収束性についてちゃんと勉強していないので、そのうち勉強したい。</p><ul><li><a href="http://www.inc.cuhk.edu.hk/InformationTheory/files/Abridged/Ch_9.pdf" target="_blank" rel="noopener">スライド</a> (by Raymond W. Yeung)</li></ul><h2 id="Information-bottleneck-method"><a href="#Information-bottleneck-method" class="headerlink" title="Information bottleneck method"></a>Information bottleneck method</h2><p>現実には歪み関数 $d$ として適切なものが何であるのか判断するのが難しい状況がある。代わりに、「ある別の変数 $Y$ に関する情報を最大限保ちつつなるべく小さな空間にエンコードする」という問題を考えるというのがinformation bottleneckの発想である。具体的には、(2) の代わりに</p><p>$$<br>    I(X, \hat{X}) - \beta I(\hat{X}, Y)<br>    \tag{3}<br>$$</p><p>を最小化する $p(\hat{x} \mid x)$ を考える。それぞれの項について考えてみると、</p><ul><li>$I(X, \hat{X})$ はもとのレート歪み理論の定式化 (2) にも出てくる項で、これが小さければ小さいほど圧縮率が高い符号を意味する。例えば、$X$ を1点集合に潰してしまうのが自明に最も短い符号だけど、このとき $I(X, \hat{X}) = 0$ となる。逆に、$X$ を無限に細かくquantizeすれば無限に高精度で復号できるが、上限値として $I(X, \hat{X}) = I(X, X) = H(X)$ にどんどん近づいていくはず。</li><li>$- \beta I(\hat{X}, Y)$ は符号化によって $Y$ の情報をなるべく失わないための正則化である。データ処理不等式から一般に $I(X, Y) \geq I(\hat{X}, Y)$ となるから、エンコード/デコードの処理で $Y$ に関する情報が増えることはない。</li></ul><p>よって、第1項を最小化することはなるべく小さく圧縮することを目指すのに対して、第2項を最小化することはなるべく元の情報を保つことを目指すので、どこかに均衡点が発生する。</p><p>Information bottleneckの式 (3) の停留条件を書くと、</p><p>$$<br>    p(\hat{x} \mid x) \propto p(\hat{x}) \exp( - \beta D_{KL}(p(y \mid x) \parallel p(y \mid \hat{x})))<br>$$</p><p>となる。よって、information bottleneck法では、結果的に $D_{KL}(p(y \mid x) \parallel p(y \mid \hat{x}))$ を歪み関数として採用したことになっているといえる。</p><p><a href="https://arxiv.org/abs/physics/0004057" target="_blank" rel="noopener">元論文</a> では、(3) を解くためのBlahut–Arimoto型のアルゴリズムも与えられている。</p><h1 id="次回メモ"><a href="#次回メモ" class="headerlink" title="次回メモ"></a>次回メモ</h1><p>もともと、最近の機械学習 or 深層学習の文脈で、information bottleneckが (思想として) どう理解されているのか気になったので、次回はより最近の論文をランダムに読みます。特に、深層学習の汎化の説明として、Tishby and Zaslavsky (2015) がinformation planeという概念を導入しており、そのあたりの整理が目標です。</p><ul><li>Tishby and Zaslavsky (2015). Deep Learning and the Information Bottleneck Principle. <a href="https://arxiv.org/abs/1503.02406" target="_blank" rel="noopener">(URL)</a></li><li>Shwartz-Ziv and Tishby (2017). Opening the Black Box of Deep Neural Networks via Information. <a href="https://arxiv.org/abs/1703.00810" target="_blank" rel="noopener">(URL)</a></li><li>Saxe et al. (2018). On the Information Bottleneck Theory of Deep Learning. <a href="https://openreview.net/forum?id=ry_WPG-A-" target="_blank" rel="noopener">(URL)</a></li><li>Alemi et al. (2016). Deep Variational Information Bottleneck. <a href="https://arxiv.org/abs/1612.00410" target="_blank" rel="noopener">(URL)</a></li><li><a href="https://github.com/yoheikikuta/paper-reading/issues/28" target="_blank" rel="noopener">yoheikikutaさんのメモ (The information bottleneck method)</a></li><li><a href="https://github.com/yoheikikuta/paper-reading/issues/26" target="_blank" rel="noopener">yoheikikutaさんのメモ (Deep Learning and the Information Bottleneck Principle)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Information bottleneck関係の個人的勉強メモです。&lt;/p&gt;
&lt;p&gt;ブログでは、書くことの心理障壁を下げるために以前よりも勉強内容を小出しにしていくことを考えており、今日の目標は以下の元論文の主張をまとめておくことです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tish
      
    
    </summary>
    
      <category term="2020/3" scheme="http://ktrmnm.github.io/blog/categories/2020-3/"/>
    
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
      <category term="個人用メモ" scheme="http://ktrmnm.github.io/blog/tags/%E5%80%8B%E4%BA%BA%E7%94%A8%E3%83%A1%E3%83%A2/"/>
    
      <category term="情報理論" scheme="http://ktrmnm.github.io/blog/tags/%E6%83%85%E5%A0%B1%E7%90%86%E8%AB%96/"/>
    
  </entry>
  
  <entry>
    <title>最近出した論文 (劣モジュラ正則化とかGANとか)</title>
    <link href="http://ktrmnm.github.io/blog/2020/03/21/20200321-recent-publications/"/>
    <id>http://ktrmnm.github.io/blog/2020/03/21/20200321-recent-publications/</id>
    <published>2020-03-21T06:46:55.000Z</published>
    <updated>2020-03-22T06:59:42.350Z</updated>
    
    <content type="html"><![CDATA[<p>ブログを約2年放置してしまいました (前回は2018/4/30)。</p><p>この2年ほどのあいだに、自分の環境 (職場、家庭、学位) がいろいろ変わって大変でした。しかしそろそろ仕事以外の勉強も再開していきたいので、リハビリがてら色々書いていこうと思います。</p><p>久しぶりすぎて何から書き始めるか迷ったのですが、自分が関わった論文が直近1年の間に何本か出たので、それらについて書きます。</p><h1 id="劣モジュラ正則化"><a href="#劣モジュラ正則化" class="headerlink" title="劣モジュラ正則化"></a>劣モジュラ正則化</h1><p>劣モジュラ正則化 (submodular regularization) というテーマで論文を2つ書きました。これは自分の博士課程の研究です。</p><p>劣モジュラ正則化とは何かというと、LassoとかGroup lasso, Fused lassoのような凸正則化法を拡張した概念です。これらの正則化法は、推定したいパラメータに対する構造的スパース性 (structured sparsity) を誘導するものです。例えば、線形回帰におけるLassoは</p><p>$$<br>  \min_{\theta \in \mathbb{R}^p} \frac{1}{2} | y - X \theta |^2_2 + \lambda | \theta |_1<br>$$</p><p>というような凸最適化問題の解として定義されるものですが (※記号の説明は略)、ここでL1正則化項はパラメータ $\theta$ に対するcoordinate sparsity (いわゆる普通のsparsity) を誘導します。しかし、もっと「構造のあるスパース性」を考えることもできます。例えば、generalized fused lassoという手法では</p><p>$$<br>  \sum_{(i, j) \in E} |\theta_i - \theta_j|<br>$$</p><p>という正則化項を利用しますが、これは与えられたグラフ $G = (V, E)$ 上で区分的に定数となるような性質を誘導します。</p><p>こういった正則化項が、実は <a href="https://en.wikipedia.org/wiki/Submodular_set_function" target="_blank" rel="noopener">劣モジュラ関数</a> と関係があるということを指摘した <a href="https://papers.nips.cc/paper/3933-structured-sparsity-inducing-norms-through-submodular-functions" target="_blank" rel="noopener">2010年の論文</a> があります。具体的には、Lasso, Group lasso, Fused lassoといったような代表的な手法も含む比較的広いクラスの正則化項が、劣モジュラ関数の凸緩和 (Lovász extension) として書けます。</p><p>このテーマについて本も出ているので、興味があればそちらを参照するのがわかりやすいかと思います。</p><ul><li>河原, 永野. <a href="https://www.kspub.co.jp/book/detail/1529090.html" target="_blank" rel="noopener">劣モジュラ最適化と機械学習</a></li><li>F. Bach. <a href="https://www.nowpublishers.com/article/Details/MAL-039" target="_blank" rel="noopener">Learning with Submodular Functions: A Convex Optimization Perspective</a></li></ul><p>こういった一般化をするひとつの利点として、proximal operator (<a href="http://ktrmnm.github.io/blog/2018/04/30/201804-proximal/">以前のブログ</a> でも書きました) の計算が劣モジュラ関数最小化と関係のあるアルゴリズムで解けるという話があります。というわけで、劣モジュラ正則化というのは、数理統計 (Lasso)、機械学習 (structured sparsityのモデリング)、離散最適化 (劣モジュラ関数最小化) のインターセクションにある研究テーマになっているというわけです。自分が博士課程に進学した当初、こういう分野横断的な話が面白そうだなと思って勉強してましたが、大学で <a href="https://www.elsevier.com/books/submodular-functions-and-optimization/fujishige/978-0-444-52086-9" target="_blank" rel="noopener">劣モジュラ関数の教科書</a> (すごく難しい) などを輪読したりしているうちに最適化の関係ない勉強が楽しくなり、どんどん脱線して収拾がつかなくなってきました。博士課程あるあるっぽい話ですが、皆さん気をつけましょう (?)</p><p>自分の研究ですが、以下のことをしました。（圧縮した説明）</p><ol><li>Degrees of freedomの研究 (<a href="https://www.sciencedirect.com/science/article/pii/S0047259X18305906?via%3Dihub" target="_blank" rel="noopener">論文はこちら</a> ): Degrees of freedomというのは、線形回帰モデルの推定量に対して定義される「実効パラメータ数」のような概念です。あるいは、fixed design regressionにおいてバイアスバリアンス分解したときの、バリアンスに相当する部分です。具体例としては、<a href="https://en.wikipedia.org/wiki/Mallows%27s_Cp" target="_blank" rel="noopener">Mallows’ Cp</a> やAICによるモデル選択では「変数の数」が罰則になりますが、実際にGaussian noiseの設定でOLSのdegrees of freedomを計算すると変数の数が出てきます。一方、degrees of freedom自体は非線形推定量に対しても定義することができて、例えば<a href="https://projecteuclid.org/euclid.aos/1194461726" target="_blank" rel="noopener">Lassoでは解の非ゼロパラメータ数と一致する</a> ことなどが知られています。この研究では、劣モジュラ正則化に対してdegrees of freedomを統一的に計算する公式を導出しています。とくに、計算するアルゴリズムが劣モジュラ関数の選択に依らず、「解の成分の中でユニークな値を数える」という方法でdegrees of freedomが計算できます (現実にはソートの計算量があればOK)。こういった「アルゴリズム的な性質」が劣モジュラ正則化に特有なところで、一般の凸正則化ではこうなるとは限らないのが面白いところです。</li><li>「区分単調信号推定」の研究 (<a href="https://arxiv.org/abs/1905.01840" target="_blank" rel="noopener">論文はこちら</a> ): <a href="https://www.stat.cmu.edu/~ryantibs/papers/neariso.pdf" target="_blank" rel="noopener">Nearly-isotonic regression</a> という手法があり、それについて解析した論文です。単調関数の推定手法で <a href="https://en.wikipedia.org/wiki/Isotonic_regression" target="_blank" rel="noopener">isotonic regression</a> という歴史ある手法があるのですが、それを正則化法に拡張した版がnearly-isotonic regressionです。もともと「単調増加である」というハードな制約があったところを、正則化法にすることによってソフトな制約として扱っているので、ある程度構造的なmisspecificationがあることも許されます。<a href="https://cran.r-project.org/web/packages/neariso/index.html" target="_blank" rel="noopener">Rのパッケージ</a> もあります。自分の研究の文脈としては、実はこのnearly-isotonic regressionは劣モジュラ正則化の一例になっているので、その事実を利用してアルゴリズムを導出したり、上の研究成果を使ってdegrees of freedomを導出したりできます。この論文としては、区分単調信号 (piecewise monotone signal) の推定という設定を考えて、その状況下でのリスクバウンドを導出したりしています。</li></ol><p>博士課程は、(つい最近の生々しい出来事なのであまり整理して語れないですが) まあまあつらかったです。能力的な意味では、自分の場合はコードを書いたり英語での論文ライティングがボトルネックになっていると感じていたので、たくさん練習しようと試みました。が、勉強とか「素振り」ばかりしていると、その間アウトプットが全然ないので、普通にどんどん心が折れていきます…。単著論文中心の研究生活だったのですが、とはいえ、自分に対する報酬の設計はうまくやったほうが精神衛生上よかったなと思いました。また、研究の一貫で劣モジュラ最小化のCython実装とかをかなり時間をかけて書いてました。これは、残念ながら論文成果にはほとんど繋がっていないのですが、劣モ最小化のプログラムは世の中にあまり存在しないはずなので、せめて整理してGithubにでも上げておきたい…が、なかなか時間がとれず、という感じであります。</p><h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p>2019年4月に<a href="https://preferred.jp/ja/" target="_blank" rel="noopener">PFN</a>という会社に入社し、業務で研究をしています。依然として論文も書いたりしており、昨年度はインターン生と書いた論文についての<a href="https://tech.preferred.jp/ja/blog/smoothness-and-stability-in-gans/" target="_blank" rel="noopener">解説記事を会社のブログに書いたりしました</a>。これはGANの理論についての研究ですが、こういった複雑なアウトプットを出せる生成モデルにはずっと興味があるので、今後も何かできたらいいなと思っています。ちなみに、論文が採択されたICLR2020はエチオピア (!) で開催されるはずだったのですが、COVID19の影響で現地開催はなくなってしまいました。どうなることやら…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ブログを約2年放置してしまいました (前回は2018/4/30)。&lt;/p&gt;
&lt;p&gt;この2年ほどのあいだに、自分の環境 (職場、家庭、学位) がいろいろ変わって大変でした。しかしそろそろ仕事以外の勉強も再開していきたいので、リハビリがてら色々書いていこうと思います。&lt;/p&gt;

      
    
    </summary>
    
      <category term="2020/3" scheme="http://ktrmnm.github.io/blog/categories/2020-3/"/>
    
    
      <category term="統計学" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%B1%E8%A8%88%E5%AD%A6/"/>
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
      <category term="日記" scheme="http://ktrmnm.github.io/blog/tags/%E6%97%A5%E8%A8%98/"/>
    
  </entry>
  
  <entry>
    <title>Backpropしないニューラルネット入門 (2/2)</title>
    <link href="http://ktrmnm.github.io/blog/2018/03/04/201803-nn-bcd/"/>
    <id>http://ktrmnm.github.io/blog/2018/03/04/201803-nn-bcd/</id>
    <published>2018-03-03T23:00:00.000Z</published>
    <updated>2020-03-01T09:20:31.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概要"><a href="#1-概要" class="headerlink" title="1. 概要"></a>1. 概要</h1><p>下記のarXiv論文を紹介します。</p><p>Jinshan Zeng, Tim Tsz-Kit Lau, Shaobo Lin, Yuan Yao (2018).<br>Block Coordinate Descent for Deep Learning: Unified Convergence Guarantees.<a href="https://arxiv.org/abs/1803.00225" target="_blank" rel="noopener">arXiv:1803.00225</a></p><p>現時点では投稿されて間もない論文ですが、個人的には機械学習の論文を読んでいて久々に楽しい気持ちになれました。</p><p>論文の提案手法はgradient-free methodと呼ばれる手法の一種なので、本記事はそのあたりのレビューも少し兼ねます。</p><h1 id="2-勾配法の収束条件"><a href="#2-勾配法の収束条件" class="headerlink" title="2. 勾配法の収束条件"></a>2. 勾配法の収束条件</h1><p>ニューラルネットの構造をひとつ固定し、その構造を使って表せる関数の全体を $\mathcal{F}$ と書きます。ニューラルネットの学習とは、与えられた損失を最小化する関数を見つけることです。例えば、二乗損失なら<br>$$<br>\hat{f} \in \arg \min_{f \in \mathcal{F}} \sum_{i=1}^n (y_i - f(x_i))^2<br>$$<br>のようになります。<a href="http://ktrmnm.github.io/blog/2018/03/04/201803-nn-generalization/">Part 1</a>で述べたとおり、この最適化問題が解けるという前提のもとで、いくつかの新しい汎化誤差バウンドが得られています。しかし、これは一般には非凸最適化となり、大域最適解へが得られることは保証できません。</p><p>現在、ニューラルネットの学習はSGD, AdaGrad, Adam, RMSPropといった勾配法ベースの最適化手法が使われていることが多く、主要な深層学習ライブラリも、勾配計算 (Backprop) の機能を提供することを主な目的としていると思います。これらの手法は、目的関数が凸であれば大域解への収束が保証されていることが多いです。</p><p>が、実際に興味のある目的関数は凸ではなく、もっというと、ReLUを使った場合は微分可能ですらありません。ちなみに、目的関数が凸でも、微分可能性のようなもの (正確にはsmoothness) は収束レートに関わることがあります。</p><p>また近年、ハードウェアへの移植などを目的として、<a href="https://arxiv.org/abs/1602.02830" target="_blank" rel="noopener">Binarized Neural Networks</a>のようにパラメータが離散的な値をとる深層学習モデルがあります。このようなモデルではそもそも勾配が存在しないため、勾配ベースの最適化アルゴリズムを直接適用することはできません。</p><h1 id="3-Block-Coordinate-Descent-BCD-ブロック座標降下法"><a href="#3-Block-Coordinate-Descent-BCD-ブロック座標降下法" class="headerlink" title="3. Block Coordinate Descent (BCD, ブロック座標降下法)"></a>3. Block Coordinate Descent (BCD, ブロック座標降下法)</h1><p>だけど、</p><ul><li>目的関数が非凸でも</li><li>微分不可能でも</li><li>勾配を使わなくても</li><li>初期値をどこに設定しても</li></ul><p>局所解に収束することを理論的に示せるよ。<strong>ブロック座標降下法</strong> ならね!!</p><h2 id="3-1-アルゴリズムの概要"><a href="#3-1-アルゴリズムの概要" class="headerlink" title="3.1. アルゴリズムの概要"></a>3.1. アルゴリズムの概要</h2><h3 id="記号"><a href="#記号" class="headerlink" title="記号"></a>記号</h3><p>$T$ 層のニューラルネットを学習する問題を抽象的に定義します。まず、</p><ul><li>$d_0, d_1, \ldots, d_T$ : ニューラルネットの各層の幅。特に、$d_0$ は入力 $x$ の次元、$d_T$ はラベル $y$ の次元と一致</li><li>$W_i \in \mathbb{R}^{d_{i} \times d_{i - 1}}$ : 第 $i$ 層のパラメータ</li><li>$\sigma_i$ : 活性化関数</li></ul><p>として、ニューラルネットで表現している関数は<br>$$<br>f(x) = W_T \sigma_{T - 1} (W_{T-1} \sigma_{T-2}(\cdots \sigma_{1}(W_1 x) \cdots ))<br>$$<br>であるとします。また、</p><ul><li>$X := [x_1, \ldots, x_n] \in \mathbb{R}^{d_0 \times n}$ : 入力データ</li><li>$Y := [y_1, \ldots, y_n] \in \mathbb{R}^{d_T \times n}$ : ラベルデータ</li><li>$\mathcal{L}(f, y)$ : 損失関数 (非負・連続だが凸とは限らない)</li></ul><p>として、経験損失を<br>$$<br>\ell(f(X); Y) := \frac{1}{n} \sum_{i = 1}^n \mathcal{L}(f(x_i), y_i)<br>$$<br>と定義します。$r_i, s_i$ を事前分布や正則化項を表す関数とします。このとき、興味のある最適化問題は、以下のような等式制約のある問題として書けます。</p><img src="/blog/2018/03/04/201803-nn-bcd/splitting.png" title="NNの最適化の3-splitting formulation"><p>なお、本来最適化すべきパラメータは $W_i$ ($i = 1, \ldots, T$) ですが、スラック変数を導入して $(W_i, V_i, U_i)$ の三つ組を最適化するという意味で、論文中では上の最適化問題を3-splitting formulationと呼んでいます。</p><h3 id="BCDアルゴリズム"><a href="#BCDアルゴリズム" class="headerlink" title="BCDアルゴリズム"></a>BCDアルゴリズム</h3><p>BCDアルゴリズムのアイデアは簡単です。まず、上記の等式制約をFrobeniusノルムによるペナルティとして表現します。</p><img src="/blog/2018/03/04/201803-nn-bcd/barrier.png" title="BCDの目的関数"><p><a href="https://en.wikipedia.org/wiki/Augmented_Lagrangian_method" target="_blank" rel="noopener">拡張ラグランジュ関数</a> から線形のラグランジュ乗数を取り除いた格好ですが、なんと呼ぶのが適切かはちょっと知りません。二次バリア関数とか？</p><p>あとは、$V_i, U_i, W_i$ のそれぞれに関する最小化をサイクリックに行うだけです。論文からアルゴリズムを引用します。</p><img src="/blog/2018/03/04/201803-nn-bcd/ZLLY18_alg1.png" title="Algorithm 1 in Zeng, et al. (2018) arXiv:1803.00225"><p>それぞれの部分問題はちょうど近接作用素を求めるような形になっており、例えば「損失 $\ell$ が2次関数、$\sigma$ がReLU、$s_i$, $r_i$ が0」といった典型的な場合ではclosed-formの解が得られます (e.g. Lemma 1)．</p><p>ニューラルネットがconvolution層を含む場合も等式制約を追加すればよいので、アルゴリズムを拡張することは容易であることが述べられています。また、ResNetに拡張した例がAlgorithm 2として提案されています。</p><p>なお、後述するように、このアルゴリズムには理論収束保証もあります。しかし、オリジナルの問題についてではなく、この $\bar{\mathcal{L}}$ が局所解に収束することを保証するものですので、その点に関しては注意が必要です。</p><h2 id="3-2-数値例"><a href="#3-2-数値例" class="headerlink" title="3.2. 数値例"></a>3.2. 数値例</h2><p>論文の数値例を紹介します。追実験などはしていません。</p><p>$T = 4$ 層のDNNでMNISTとCIFAR-10の学習を、BCDおよびSGDで行った結果の引用です。NNの構造やSGDの学習率の詳細は論文を参照してください。</p><img src="/blog/2018/03/04/201803-nn-bcd/ZLLY18_fig1.png" title="Figure 1 in Zeng, et al. (2018) arXiv:1803.00225"><p>実時間ではなくエポック数の比較ですが、SGDが学習に約100エポック必要とするのに対し、BCDは5エポック以下（！）で学習がほとんど終了していることがわかります。また、最終的なtest accuracyもSGDと比較して遜色ないものとなっています (Table 1).</p><p>定式化から明らかなようにBCDの1回の更新にかかるコストは大きく、メモリに乗らない量のデータをどう扱うかなど疑問点はありますが、promissingな結果であることは間違いないと思われます。</p><h2 id="3-3-その他のgradient-free-method-先行研究"><a href="#3-3-その他のgradient-free-method-先行研究" class="headerlink" title="3.3. その他のgradient-free method / 先行研究"></a>3.3. その他のgradient-free method / 先行研究</h2><p>先行研究に少し触れておきます。（このあたりはまだ勉強中です）。</p><p>ニューラルネットの学習をgradient-freeに行うアルゴリズムとしては、 ADMMベースの手法[1],[2],BCDベースの手法[3]が提案されています。Gradient-freeな方法の動機として、紹介論文や [1] では勾配法との比較が述べられています。計算面での主な違いは、勾配法は小さなミニバッチを使った低コストな更新を多数回行うのに対し、勾配フリー法は多くのデータを使った高コストな更新を小数回行う手法になっており、前者はGPU、後者はCPU上での実行が適しています。勾配法の収束については、勾配消失やプラトーなど既知の問題がありますが、勾配フリー法では紹介論文のような収束保証が得られています。</p><img src="/blog/2018/03/04/201803-nn-bcd/table1.png" title="勾配法と勾配フリー法の比較"><p>[1] Gavin Taylor, Ryan Burmeister, Zheng Xu, Bharat Singh, Ankit Patel, Tom Goldstein (2016).<br>Training Neural Networks Without Gradients: A Scalable ADMM Approach. In ICML2016. <a href="https://arxiv.org/abs/1605.02026" target="_blank" rel="noopener">arXiv:1605.02026</a></p><p>[2] Ziming Zhang, Yuting Chen, Venkatesh Saligrama (2016).<br>Efficient Training of Very Deep Neural Networks for Supervised Hashing. In CVPR2016. <a href="https://arxiv.org/abs/1511.04524" target="_blank" rel="noopener">arXiv:1511.04524</a></p><p>[3] Ziming Zhang, Matthew Brand (2017).<br>Convergent Block Coordinate Descent for Training Tikhonov Regularized Deep Neural Networks. In NIPS2017. <a href="https://arxiv.org/abs/1711.07354" target="_blank" rel="noopener">arXiv:1711.07354</a></p><h1 id="4-収束保証"><a href="#4-収束保証" class="headerlink" title="4. 収束保証"></a>4. 収束保証</h1><p>BCDアルゴリズムでは、$\bar{\mathcal{L}}$ が局所解に収束することが、比較的広い条件のもとで示されています。</p><h2 id="4-1-Kurdyka-Lojasiewicz-KL-条件"><a href="#4-1-Kurdyka-Lojasiewicz-KL-条件" class="headerlink" title="4.1. Kurdyka-Łojasiewicz (KL)条件"></a>4.1. Kurdyka-Łojasiewicz (KL)条件</h2><p>最近の非凸最適化の論文では、目的関数に課す正則条件としてKurdyka-Łojasiewicz (KL) propertyというものがトレンドになっているようです。まず定義を書きます</p><h3 id="記号-1"><a href="#記号-1" class="headerlink" title="記号"></a>記号</h3><p>(凸とは限らない) 関数 $f: \mathbb{R}^d \to \mathbb{R}\cup \{ + \infty \}$ の $x \in \mathbb{R}^d$ における劣勾配 $g \in \partial f(x)$ とは $(x_k, g_k) \to (x, g)$ となる点列が存在して、$f(x_k) \to f(x)$ かつ<br>$$<br>f(x^\prime) \geq f(x_k) + \langle g_k, x^\prime - x_k \rangle + o(\lVert x^\prime - x_k \rVert_2)<br>$$<br>が成り立つことをいう (正確な定義は <a href="https://arxiv.org/abs/1410.1386" target="_blank" rel="noopener">この文献</a> など)。劣勾配の集合 $\partial f(x)$ を $x$ における $f$ の劣微分という．</p><p>$\partial f(x)$ が空でない $x \in \mathbb{R}^d$ の集合を $\mathrm{dom}(\partial f)$ と書く。また、<br>$$<br>\mathrm{dist}(0, \partial f(x)) := \min\{ \lVert g \rVert_2: g \in \partial f(x) \}<br>$$<br>とする。</p><h3 id="定義：KL条件"><a href="#定義：KL条件" class="headerlink" title="定義：KL条件"></a>定義：KL条件</h3><p>関数 $f: \mathbb{R}^d \to \mathbb{R} \cup  \{ + \infty \}$ が点 $x^* \in \mathrm{dom}(\partial f)$ においてKL propertyをもつとは、3つ組</p><ul><li>$\eta \in (0, +\infty]$</li><li>$x^*$ の近傍 $U$</li><li>凹関数 $\varphi: [0, \eta) \to \mathbb{R}_+$</li></ul><p>が存在して以下の条件を満たすことをいう：</p><ol><li>$\varphi(0) = 0$, $\varphi$ は $(0, \eta)$ で $C^1$ 級</li><li>任意の $s \in (0, \eta)$ に対して $\varphi^\prime(s) &gt; 0$</li><li>任意の $x \in U \cap \{ x: f(x^*) &lt; f(x) &lt; f(x^*) + \eta \}$ に対して、次の <strong>Kurdyka-Łojasiewicz不等式</strong> が成り立つ<br>$$<br>\varphi^\prime(f(x) - f(x^*)) \mathrm{dist}(0, \partial f(x)) \geq 1.<br>$$</li></ol><p>KL不等式が何を言っているかというのが問題ですね。KL条件の意味については<a href="http://www.gipsa-lab.fr/summerschool/slra2015/BolteGrenoble.pdf" target="_blank" rel="noopener">このスライド</a> がわかりやすいです。(確か、以前tmaeharaさんに教えていただいたものです)</p><p>まず、$0 \in \partial f(x)$ というのは $x$ が $f$ の停留点であるということなので、逆に $\mathrm{dist}(0, \partial f(x))$ が大きいならば点 $x$ において $f$ が大きく傾いているということを表します。もし $f$ の等高線でスライスした領域 $\{ x: a &lt; f(x) &lt; b \}$ において一様に $\mathrm{dist}(0, \partial f(x)) \geq c &gt; 0$ が成り立つのであれば、関数の「谷」のような部分に向かって急に落ち込んでいるものと考えられます。</p><img src="/blog/2018/03/04/201803-nn-bcd/Bolte_2015_sharp_function.png" title="Figure from Bolte (2015)"><p>(図は <a href="http://www.gipsa-lab.fr/summerschool/slra2015/BolteGrenoble.pdf" target="_blank" rel="noopener">Bolte(2015)</a> から引用)</p><p>この性質が成り立つとき、$f$ はこのスライスにおいてsharpである、ということにします。もし $f$ がsharpであれば、近接点法のようなアルゴリズムは有限ステップで「谷底」のような部分に到達できます (ラフな証明は <a href="http://www.gipsa-lab.fr/summerschool/slra2015/BolteGrenoble.pdf" target="_blank" rel="noopener">Bolte(2015)</a> p.17)。</p><p>KL条件は、本質的には<br>$$<br>\mathrm{dist}(0, \partial(\varphi\circ (f(x) - f(x^*)))) \geq 1<br>$$<br>と等価です。これは、凹関数 $\varphi$ によって、等高線のスライスを高さ $f(x^*)$ の「谷底」に近づける速さをコントロールしたときにsharpと見做せる、ということを述べています。よって、なんとなくですが、$f$ 自身が凸でなくても、谷底に到達する何らかの手段は手に入るような感じがします。</p><h3 id="KL条件を満たす関数"><a href="#KL条件を満たす関数" class="headerlink" title="KL条件を満たす関数"></a>KL条件を満たす関数</h3><p>重要な点は、実はかなり多くの関数がKL条件を満たすことがわかります。というか、「KL条件を満たす関数がたくさんある」ということそのものがこの理論の根幹をなす結果になっているようです。</p><ul><li>解析関数はKL条件を満たす。</li><li>グラフが半代数的集合になる関数を半代数的関数 (semialgebraic function) という。すべての半代数的関数はKL条件を満たす。</li><li>半代数的関数は有限個の和や積、合成などの操作で閉じる。</li></ul><p>例えば、2次関数やReLUなどは半代数的関数なのでKL条件を満たします。よって、それらの和・積・合成によってできている訓練損失もKL条件を満たすことが示せます (Proposition 1)。</p><h3 id="KL条件から何が言えるか"><a href="#KL条件から何が言えるか" class="headerlink" title="KL条件から何が言えるか"></a>KL条件から何が言えるか</h3><p>ずばり、近接点法や座標降下法のようなアルゴリズムの収束保証と収束レートの導出に使えます[4] [5]。具体的には、近接点法では $\varphi(s) = c s^(1- \theta)$ ($\theta \in [0, 1)$) のような形をしているとき、$\theta = 0$ なら有限ステップで停留点に収束、$0 &lt; \theta \leq 1/2$ ならば誤差が $O(\exp(-k))$ で収束、$1/2 &lt; \theta &lt; 1$ ならば $O(k^{-(1 - \theta)/(2\theta - 1)})$ で収束、という結果が得られており [4]、紹介論文でもこの結果に帰着することで収束レートを出しています。</p><p>[4] Hedy Attouch, Jérôme Bolte (2009).<br>On the convergence of the proximal algorithm for nonsmooth functions involving analytic features. Mathematical Programming, 116, 5–16. <a href="https://pdfs.semanticscholar.org/5913/62ef83ce9050159ab8c9b70f8cf8e7c8319d.pdf" target="_blank" rel="noopener">プレプリント</a></p><p>[5] Hedy Attouch, Jérôme Bolte, Benar Fux Svaiter (2013).<br>Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward–backward splitting, and regularized Gauss–Seidel methods. Mathematical Programming, 137, 91–129. <a href="https://link.springer.com/article/10.1007/s10107-011-0484-9" target="_blank" rel="noopener">URL</a></p><h2 id="4-2-BCDの収束"><a href="#4-2-BCDの収束" class="headerlink" title="4.2. BCDの収束"></a>4.2. BCDの収束</h2><p>DNNに対するBCDの収束は次のことが示せます。($\bar{\mathcal{L}}$ の収束であることに注意)</p><p><strong>仮定</strong></p><ul><li>$i = 1, \ldots, T-1$ について、活性化関数 $\sigma_i$ は $L$-Lipschitzである</li><li>関数 $\bar{\mathcal{L}}$ はある点でKL条件を満たす。特に、(a) $s_i, r_i$ が半代数的関数であり、(b) 損失関数が2乗損失、ロジスティック損失、ヒンジ損失のいずれかであり、(c) 活性化関数がReLU、シグモイド、線形リンクのいずれかであれば、どの組み合わせでもこの条件は満たされる。</li></ul><p><strong>Theorem 2 (要点のみ)</strong><br>上の仮定が成り立つとする。BCDアルゴリズムの第 $k$ ステップでの出力を $P^k$ とする。</p><ol><li>BCDアルゴリズムにおいて、$\mathrm{dist}^2(0, \partial \bar{\mathcal{L}}(P^k))$ のrunning best rate ($k$ステップまでの最良値) は $o(1/k)$ である。</li><li>関数 $\bar{\mathcal{L}}$ がある点において、$\varphi(s) = c s^{1 - \theta}$ に対してKL条件を満たすならば、停留点への収束レートが得られる。</li></ol><h1 id="5-結論"><a href="#5-結論" class="headerlink" title="5. 結論"></a>5. 結論</h1><p>現在、「GPUに廃課金して勾配法で殴る」という手法が主流になっていると思われますが、これを機に今後はgradient-freeな手法にも期待できるかもしれません。</p><p><blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">深層学習の一般論を講義するのに、 いやがるニューラルネットにわざわざbackpropする必要があるでしょうか？ニューラルネットにも命があります。 命あるものを粗末に扱うことは許されません。</p>&mdash; 某ことり (@ktrmnm) <a href="https://twitter.com/ktrmnm/status/969581746319585280?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">2018年3月2日</a></blockquote></p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><p><a href="http://www.ms.u-tokyo.ac.jp/~kawazumi/spcm.html" target="_blank" rel="noopener">(参考)</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-概要&quot;&gt;&lt;a href=&quot;#1-概要&quot; class=&quot;headerlink&quot; title=&quot;1. 概要&quot;&gt;&lt;/a&gt;1. 概要&lt;/h1&gt;&lt;p&gt;下記のarXiv論文を紹介します。&lt;/p&gt;
&lt;p&gt;Jinshan Zeng, Tim Tsz-Kit Lau, Shao
      
    
    </summary>
    
      <category term="2018/3" scheme="http://ktrmnm.github.io/blog/categories/2018-3/"/>
    
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
      <category term="深層学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/"/>
    
      <category term="最適化" scheme="http://ktrmnm.github.io/blog/tags/%E6%9C%80%E9%81%A9%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Backpropしないニューラルネット入門 (1/2)</title>
    <link href="http://ktrmnm.github.io/blog/2018/03/04/201803-nn-generalization/"/>
    <id>http://ktrmnm.github.io/blog/2018/03/04/201803-nn-generalization/</id>
    <published>2018-03-03T20:08:59.000Z</published>
    <updated>2020-03-01T09:20:31.245Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>最近、統数研で行われた<a href="https://ismseminar.github.io/fimi2018/" target="_blank" rel="noopener">関数推論のワークショップ</a>を聴講したり、面白いarXiv論文に出会ったりしまして、深層学習の理論への個人的な関心が高まってきました。そこで、いくつか関心があることをブログにまとめようと思います。</p><p>タイトルはほぼ釣りですが、</p><ul><li>今回は「最適化マターをすべて無視した場合の汎化理論」</li><li>次回は「Backpropしない最適化手法」</li></ul><p>という予定なので、そこまで間違ってはいないつもりです。ちなみに、網羅的なレビューではありません。</p><h1 id="汎化というミーム"><a href="#汎化というミーム" class="headerlink" title="汎化というミーム"></a>汎化というミーム</h1><p>機械学習の研究は「手法そのものの基礎研究」という側面がありますので、深層学習の研究の目標としては</p><ol><li>なぜ深層学習がうまくいっているように見えるのか</li><li>どうすれば「理論保証つきで」もっとうまくいくのか</li></ol><p>ということはぜひ解明されるべきかと思います。（もちろん、一枚岩の分野ではなく、応用研究が重要です）。</p><p>「なぜうまくいくのか」というのは、汎化 (generalization) の理論を掘りすすめるということです。</p><p>今までの統計的機械学習は、汎化というパラダイムとともにずっと歩んできました。汎化というのは、「手元にあるデータがとある未知の法則から発生したものであるとき、同じ法則から発生するであろう未来のデータをうまく説明できる能力」です。もう少し現場で使われている表現だと、test accuracyが良くなる状態というのが汎化といえます。</p><p>そして、よい学習とモデルの複雑さにはトレードオフの関係があります。</p><ul><li>理論的には、リスクや<a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory" target="_blank" rel="noopener">汎化誤差の上界</a>に「モデルの大きさ」に相当する項が含まれてしまうため、トレードオフを考慮して <strong>モデルはなるべく小さく選ぶ</strong>、というのが<a href="https://ja.wikipedia.org/wiki/%E8%B5%A4%E6%B1%A0%E6%83%85%E5%A0%B1%E9%87%8F%E8%A6%8F%E6%BA%96" target="_blank" rel="noopener">AIC</a>以来の世界観になっています。</li><li>経験的にも、訓練誤差が良いのにテスト誤差がとても悪いという現象（過学習）があることが良く知られていて、モデル選択や正則化といったツールが実務上も欠かせない存在になっています。</li></ul><p>しかし、「汎化」や「過学習しないようにモデルは小さく」というのはあくまで <strong>ミームではあるものの公理ではなく</strong>、現実にはもっと色々なことがありえます。</p><p>例えば深層学習では、標準的な意味ではモデルが大きすぎるが、依然として<a href="https://arxiv.org/abs/1611.03530" target="_blank" rel="noopener">うまく行っているように見える現象が報告</a>されるなど、従来からの「過学習のストーリー」には乗らない例が増えていますし、それに伴って <a href="https://arxiv.org/abs/1710.05468" target="_blank" rel="noopener">汎化の定義を再考する試み</a> なども行われています。要するに、「こういう指針でやればだいたいの場合うまく行く」という思想のようなものをアップデートする必要が出てきている、ということかと認識しています。</p><h1 id="2018年の汎化理論：関数クラスの拡大"><a href="#2018年の汎化理論：関数クラスの拡大" class="headerlink" title="2018年の汎化理論：関数クラスの拡大"></a>2018年の汎化理論：関数クラスの拡大</h1><p>ここで、ちょっと回帰の問題を考えてみます。</p><p>データとして、$(x_i, y_i)$ ($i = 1, \ldots, n$) という入出力ペアが与えられたとします。真の法則は $y_i = f(x_i) + noise$ というな形をしているとして、関数 $f(x)$ を推定する問題を考えます。</p><p>ニューラルネットの構造を適当にひとつ固定して、パラメータを変えることで表現できる関数の全体を $\mathcal{F}$ としたとき、最小二乗法によるフィット<br>$$<br>\hat{f} \in \arg \min_{f \in \mathcal{F}} \sum_{i=1}^n (y_i - f(x_i))^2<br>\tag{1}<br>$$<br>によって関数を推定することができます。明示的な正則化などは、数式の上ではひとまず考えないことにします。</p><p>この最小化問題が厳密に解けたと仮定して、予測誤差の意味でどれだけよいかを考えます。</p><p>統計学においては、このような問題は、いわゆるノンパラメトリック回帰と呼ばれている分野の守備範囲でした。ノンパラ回帰の理論は、「関数が滑らかである（与えられた回数微分可能である）」という仮定に負っていた部分が多く、最適性などもその範疇で考えられてきました。しかし、このままでは、ニューラルネットを学習して作った関数$\hat{f}$ が「他と比べてことさらに良い」ことの理由を答えるのが難しくなってしまいます。仮定が現実と合わなくなったケースですね。</p><p>そこで、関数が大域的に滑らかであるという仮定から離れ、現実のデータに即して「よりカスタマイズされた関数構造」を考えることでニューラルネットの良さを説明しよう、というアイデアがあります。この流れで、前述の<a href="https://ismseminar.github.io/fimi2018/" target="_blank" rel="noopener">統数研ワークショップ</a> の講演の中から最近の研究を挙げると：</p><ul><li><a href="https://arxiv.org/abs/1708.06633" target="_blank" rel="noopener">Schmidt-Hieber (2017)</a> では、疎な入力をもつ滑らかな関数のcompositionで書けるクラス （<a href="http://pub.math.leidenuniv.nl/~schmidthieberaj/research.html" target="_blank" rel="noopener">紹介ページ</a>）</li><li><a href="https://arxiv.org/abs/1705.10182" target="_blank" rel="noopener">Suzuki (2017)</a> では、ある積分作用素の固有値の減衰が速い関数クラス</li><li><a href="https://arxiv.org/abs/1802.04474" target="_blank" rel="noopener">Imaizumi &amp; Fukumizu (2018)</a> では、区分的に滑らかな関数クラス（<a href="https://sites.google.com/view/mimaizumi/research/kaisetsu" target="_blank" rel="noopener">紹介ページ</a>）</li></ul><p>といったように、従来の仮定とは異なる構造をもった関数クラスに対する汎化能力が議論されるようになっています。</p><p>ところで、最適化問題 (1) は非凸最適化になり、一般には大域最適解を得ることができません (computableかどうかわからない)。最適化の問題が絡んだ場合の情報はかなり錯綜している印象で、「実はすべての局所解は大域解だから最適化の問題はない」「SGDなどの特定のアルゴリズムが汎化の意味でよい局所解を自動的に選択するから問題ない」などの意見があるようです（文献は割愛）。</p><h1 id="感想：何がうまくいっていないか"><a href="#感想：何がうまくいっていないか" class="headerlink" title="感想：何がうまくいっていないか"></a>感想：何がうまくいっていないか</h1><p>従来の考え方のままでは、現状何がうまくいかなくなっているのかを考えてみると、要するに</p><ol><li>理論で使われていた仮定が現実と合わなくなった（定式化の欠陥）</li><li>不安定な方法やヒューリスティックスに頼っている（アルゴリズムの欠陥）</li></ol><p>ということなんじゃないかなあと思います。</p><p>定式化に欠陥があると、理論的に最適な手法と現実に起きていることにズレが生じますし、どんなに解析を精密にしても深層学習が強い理由はそこにはない、ということになってしまいます。そこで、上でレビューしたように、新しい適切な問題設定を探すということが理論面での大きな目標のひとつになるのかな、という所感です。</p><p>また、アルゴリズムが不安定だと結果の再現性がなくなってしまいます。そうすると分野全体としても、いろいろな結果から示唆を得て新しい思想を固める作業に時間がかかってしまう気がします。会議の締め切り前になると、エポックごとに誤差が上がった下がったと一喜一憂する人々の姿が世界各地で見られるそうですが、やはり、最適化手法の側にも理論保証がついていないと安心して夜も眠れないのではないかと思います。</p><p>というわけで次回はアルゴリズムの話を書きたいです。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;最近、統数研で行われた&lt;a href=&quot;https://ismseminar.github.io/fimi2018/&quot; ta
      
    
    </summary>
    
      <category term="2018/3" scheme="http://ktrmnm.github.io/blog/categories/2018-3/"/>
    
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
      <category term="深層学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/"/>
    
  </entry>
  
  <entry>
    <title>SODA&#39;18読み会に参加した</title>
    <link href="http://ktrmnm.github.io/blog/2018/03/04/201803-soda18yomi/"/>
    <id>http://ktrmnm.github.io/blog/2018/03/04/201803-soda18yomi/</id>
    <published>2018-03-03T20:00:00.000Z</published>
    <updated>2020-03-01T09:20:31.245Z</updated>
    
    <content type="html"><![CDATA[<p>先月ですが、理研AIPで<a href="https://sites.google.com/view/soda2018reading" target="_blank" rel="noopener">SODA2018読み会</a>なるものが開催されたので、自分も論文を読んできました。</p><p>読んだ論文：<br>Blais, et al. (2018) Tolerant Junta Testing and the Connection to Submodular Optimization and Function Isomorphism <a href="https://arxiv.org/abs/1607.03938" target="_blank" rel="noopener">(URL)</a></p><p>スライド：</p><script async class="speakerdeck-embed" data-id="72fe827e5eb345748a810784874d847e" data-ratio="1.41436464088398" src="//speakerdeck.com/assets/embed.js"></script><p>内容としては性質検査 (property testing) という分野に属する研究で、与えられたブール関数がk-juntaという性質をもつかどうかを、入力長によらない定数時間で判定するアルゴリズムを提案したものです。（もう少し正確には、tolerant testingという設定で、kの多項式回のクエリアクセスでの検査が可能であることが示された点が新しいです）。</p><p>個人的には、SODA (理論CS) の論文にちゃんと触れるのは初めてだったので、どの発表もとても勉強になりました。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先月ですが、理研AIPで&lt;a href=&quot;https://sites.google.com/view/soda2018reading&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SODA2018読み会&lt;/a&gt;なるものが開催されたので、自分も論文を読んでき
      
    
    </summary>
    
      <category term="2018/3" scheme="http://ktrmnm.github.io/blog/categories/2018-3/"/>
    
    
      <category term="勉強会" scheme="http://ktrmnm.github.io/blog/tags/%E5%8B%89%E5%BC%B7%E4%BC%9A/"/>
    
  </entry>
  
  <entry>
    <title>機械学習アルゴリズムをテストしたい</title>
    <link href="http://ktrmnm.github.io/blog/2018/03/04/201803-mlcode-test/"/>
    <id>http://ktrmnm.github.io/blog/2018/03/04/201803-mlcode-test/</id>
    <published>2018-03-03T18:30:00.000Z</published>
    <updated>2020-03-01T09:20:31.232Z</updated>
    
    <content type="html"><![CDATA[<h1 id="動機"><a href="#動機" class="headerlink" title="動機"></a>動機</h1><p>論文などを読みながら機械学習のアルゴリズムを実装していると、</p><ul><li>出力が浮動小数点数の巨大な配列である</li><li>出力がランダムに決まる</li><li>テストケースに対する正しい出力を手計算するのが不可能</li><li>そもそもアルゴリズムを自分が理解してない（死）</li></ul><p>とかの理由で、書いたコードが正しいかどうか全然わからないです。そして、だいたい正しくないです。</p><p>本当は小さい単位でテストしながら書きたいのですが、何がベストプラクティスなのかよく知らないし、とりあえず試したことのメモを蓄積することにしました。</p><h1 id="書いたもの（随時更新）"><a href="#書いたもの（随時更新）" class="headerlink" title="書いたもの（随時更新）"></a>書いたもの（随時更新）</h1><ul><li><a href="https://qiita.com/ktrmnm/items/667a7b7c93cd3fb78419" target="_blank" rel="noopener">Google Test勉強録 (1) CMakeでのビルド</a></li><li><a href="https://qiita.com/ktrmnm/items/a9c9d9eed9ea2d9cebdc" target="_blank" rel="noopener">Google Test勉強録 (2) アルゴリズムのテストを書く</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;動機&quot;&gt;&lt;a href=&quot;#動機&quot; class=&quot;headerlink&quot; title=&quot;動機&quot;&gt;&lt;/a&gt;動機&lt;/h1&gt;&lt;p&gt;論文などを読みながら機械学習のアルゴリズムを実装していると、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;出力が浮動小数点数の巨大な配列である&lt;/li&gt;
&lt;l
      
    
    </summary>
    
      <category term="2018/3" scheme="http://ktrmnm.github.io/blog/categories/2018-3/"/>
    
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
      <category term="C++" scheme="http://ktrmnm.github.io/blog/tags/C/"/>
    
      <category term="TDD" scheme="http://ktrmnm.github.io/blog/tags/TDD/"/>
    
  </entry>
  
  <entry>
    <title>[意訳] FOCS著者へのアドバイス (CS理論系論文の書き方)</title>
    <link href="http://ktrmnm.github.io/blog/2017/01/30/201701-focs-advice/"/>
    <id>http://ktrmnm.github.io/blog/2017/01/30/201701-focs-advice/</id>
    <published>2017-01-30T13:55:39.000Z</published>
    <updated>2020-03-01T09:20:31.232Z</updated>
    
    <content type="html"><![CDATA[<p>この文章は、Boaz Barak教授 (現: Harvard大) による2014年のブログ<br><a href="https://windowsontheory.org/2014/02/09/advice-for-focs-authors/" target="_blank" rel="noopener">Advice for FOCS authors</a><br>を意訳したものです。</p><p>FOCSは、STOCなどと並ぶコンピュータサイエンスの理論系トップ会議です。情報系の分野ではなぜか、国際会議に採択されることがメインの業績として扱われることが多いです。（論文が論文誌に投稿されないので、他分野から見ると「え、何で論文書いてないの」のような反応がしばしば見受けられます。）</p><p>しかし、情報系と一口に言っても、研究の進むスピードは分野によってさまざまです。<br>機械学習などでは、分野としては非常に速いスピードでトレンドが流れていく印象があります。近年は深層学習ブームと言われていますが、arXivに投稿した論文が次の日に他のグループによって引用されている、というような極端な話を方々で耳にします。そういった時間感覚を持つ分野では、年に一度や二度の国際会議ですら情報の速報性が足りない、ということを言う人もいます。</p><p>こういった、「イケてる・速い・競争的・採択率低い」世界に論文を通す技術として、どうやらある特定の方向性のプレゼンテーション能力が要求されてるっぽいぞ、というコンセンサスがなんとなく共有されているように思います。<br>例えば、下記のredditは一時期流行ったものです。<br><a href="https://www.reddit.com/r/MachineLearning/comments/3x3urc/tips_on_publishing_in_nips_icml_or_any_top_tier/cy1aw8o/" target="_blank" rel="noopener">Tips on publishing in NIPS, ICML or any top tier conferences for ML</a><br>内容はほぼほぼ自虐ネタですが、うかつに無視できない部分があったりして大変つらい。<br>個人的に心が痛いのは2と3でして、</p><ul><li>機械学習トップ会議に通すには定理は1つか2つあったほうがいい。内容は問わない。査読者は定理が好きだから。</li><li>数学はいいぞ。でもバランスが必要で、数式が多すぎてはだめ。もし数式が多すぎるならCOLT（注：学習理論の会議）に投稿すべきだ。もし数式がないなら、シグモイドとかソフトマックス関数の定義式を別行立て数式で載せときゃいい。</li></ul><p>とのこと。</p><p>一方、理論系のコミュニティに目を向けると、かなり違う印象を受けます。</p><p>CSの理論研究は基本的には「定理と証明」の地道な繰り返しによって成り立っています。よって、どちらかというと数学系の論文誌と似たような精度で、数学的なステートメントの正しさが検証されます。（応用研究では証明が検証されない、という意味ではないです。）<br>それにもかかわらず、学会の開催頻度は情報系の他の分野と同じです。このため、投稿者はハードな締め切りまでに理論的な貢献を含む論文を書かなければならず、査読者も、一年のある期間に集中して大量の論文を読まなければならないという現象が起きていると考えられます。</p><p>表題のブログは、私が把握している限りでは、CS分野の理論研究の論文を書くにあたっての注意点を紹介している数少ない記事でした。特に、<strong>情報系の会議文化のなかで、定理と証明が主体の論文を書くというのはどういうことか</strong> ということがわかって、個人的には勉強になっています。</p><p>以下は引用です。本記事では、導入とサマリーを除いた主要な部分のみを意訳しています。</p><h1 id="読者のことを考える"><a href="#読者のことを考える" class="headerlink" title="読者のことを考える"></a>読者のことを考える</h1><p>FOCSの投稿論文、そして任意の科学論文を書くにあたって最もチャレンジングなことのひとつは、様々なタイプの読者に同時に対処することです。網羅的ではありませんが、次のようなタイプの読者が含まれると思ってください。</p><p>(1) その分野の専門家。あなたのアプローチが彼らの2007年の論文と比べてどう異なるのか、全て詳細に検証したい読者です。<br>(2) 専門家ではない査読者。あなたのやったことは何なのか、なぜその問題が解きたいのか、論文で使われているテクニックに関して、何らかのとっかかりを掴みたい読者です。<br>(3) あなたの論文にアサインされたPCメンバー。論文を数分間だけ流し読みして、上記の内容の近似を得たい読者です。</p><p>これらの異なる読者に対処するためのおおよその方針としては、<strong>前半の数セクションはコンピュータサイエンス理論の一般的な読者でも理解できるように書き、専門家に向けた詳細は後半のセクションに含まれるようにする</strong> ことです。この方針は次の視点を導きます。</p><h1 id="全力を出せ-Put-your-best-foot-forward"><a href="#全力を出せ-Put-your-best-foot-forward" class="headerlink" title="全力を出せ (Put your best foot forward)"></a>全力を出せ (Put your best foot forward)</h1><p>(2014年現在) FOCSにはページ数制限はありませんが、査読者も投稿論文の全てを読まなくてよい規定になっています。これが実際に意味するところは、私が「Impagliazzoのルール」と呼んでいるものに従うべきということです。つまり、<strong>任意のXに対して、論文の最初のXページを、読者が次のXページを読みたくなるように書く</strong> べきです。</p><p>特に、あなたの結果、テクニック、研究の動機、研究が置かれている文脈、および先行研究と比較した新規性が、論文中の早い段階で明確に述べられるように心がけるべきです。もし、主定理を簡潔に述べるのが難しいならば、その主定理の正式でない版または重要な具体例をまず述べて、完全なステートメントが書いてある箇所を後方参照する、という方法があります。</p><p>上の方法は結果だけでなくテクニックについても適用できます。あなたの素晴らしいアイデアを、テクニカル・セクションまで取っておく必要はありません。最もよく書けている論文の中には、イントロに続いて “Our techniques”, “Proof outline”, “Warmup”, “Toy problem” といった章が設けてあることがあり、証明の背後にあるアイデアを非正式な形でわかりやすく説明しています。</p><p>謙虚さは良いことですが、FOCSの投稿にあたってはそれを徹底する必要はありませんし、あなたの貢献を論文の端っこの方に隠してしまう必要はないのです。逆に、貢献を喧伝しすぎるということも、もちろんしたくありません。</p><p>というわけで…</p><h1 id="さらけ出せ-Put-your-worst-foot-forward"><a href="#さらけ出せ-Put-your-worst-foot-forward" class="headerlink" title="さらけ出せ (Put your worst foot forward)"></a>さらけ出せ (Put your worst foot forward)</h1><p>科学者としては、自分の研究内容について欠陥の可能性・注意点・改善の余地がちゃんと見えるように身をかがめる姿勢をとりたいものです。FOCSの著者にもその姿勢が欠けていないことを期待します。</p><p>主結果がとても制限された状況でしか成り立たない、ということが、論文のSection 4を読んだ段階でようやく発覚したりすると、査読者にとってはめちゃくちゃ腹が立ちます。すべての制限・注意点・仮定・限界は論文の早い段階で述べられるべきです。実際、いくつかの注意点は非常にメジャーなので、イントロで言及してもまだ遅いということがあります。例えば、あなたが単調回路 (monotone circuit) でのみ成立する下界を証明した場合、アブストラクトではっきりとそう書くだけでなく、monotone という単語をタイトルに入れるべきです。一般的に、問題をより簡単にするためのモデルの仮定を選んだならばそれについて議論すべきで、別のモデルを選んだ場合にどのような変更点が生じるか説明すべきです。</p><p>同様に、先行研究との任意の関係およびオーバーラップは論文の早い段階で述べるべきです。もし、結果が先行研究の一般化であるならば、それらがどのように異なるのか、また、そのような一般化を行う動機について説明しましょう。結果があるパラメータについては改善になっているが、他のパラメータについては改善になっていないのであれば、それらの重要性についての議論を行うことが適切です。関連研究の存在を知っているならば、それが仮に出版されていなかったり、あなたの仕事の後になされていたとしても、なおも引用した上で、それらの関連性や前後関係を説明しましょう。</p><h1 id="疑わしきを排除せよ"><a href="#疑わしきを排除せよ" class="headerlink" title="疑わしきを排除せよ"></a>疑わしきを排除せよ</h1><p>科学論文は小説ではありません。理想的には、読者が疑いの中にとどまってしまうことや、良い意味でも悪い意味でも驚きが生じたりすることは、起こらないべきです。FOCSのPCメンバーは信じられないくらい才能のある集団ですが、それでもなお、読者が抱きそうなすべての疑問点と誤解を予測しつつ “foolproof” なやり方で論文が書かれるべきです。（特に、限られた時間のなかで40本もの論文を査読しなければならないような読者についてはそうです）。</p><p>例えばですが、査読コメントに「主定理の証明はXを使えば非常に簡易化できるだろう」と書いてあって、しかしそのXというのがあなたが最初に試してみてうまくいかなかった方法だったりすると、著者にとっては非常に腹立たしいことだと思います。これを避けるには、 “First attempt” というタイトルの章を設けてXについて議論し、なぜうまくいかないか説明するという方法があります。同様に、一見するとあなたの仕事に関係がありそうだが実際には関係がない論文が存在する場合は、それをなお引用して、なぜ「実際には関係がない」のか説明するべきです。</p><p>他には、査読が「シンプルすぎるのでリジェクト」っぽいことを述べているときもムカつきますね。私や他のFOCS PCメンバーは単純さは美徳であると信じていますから、それが原因でリジェクトにすることはありません。しかし、論文が単純すぎて査読者に驚かれるということを避けたいのであれば、証明が先行研究のものに対して「3行の短縮」になっていることを論文の後半のほうで議論します。もし証明が単純なのであれば、それは誇るべきことなので初めからそう言いましょう。もし特定の補題の証明が標準的な手法におけるルーチンの適用であるならば、それは削らずに書くかappendixに移動しましょう。ただし、この場合は証明の最初の部分でそのことを説明し、詳細を追うことをあまり目的としていない査読者が読み飛ばせるようにしましょう。このことは他の場合にも当てはまります。証明中に奇抜な飛躍点 / 些細な点があるならば、そうであることを告げる文章を追加して読者にわかるようにしましょう。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;この文章は、Boaz Barak教授 (現: Harvard大) による2014年のブログ&lt;br&gt;&lt;a href=&quot;https://windowsontheory.org/2014/02/09/advice-for-focs-authors/&quot; target=&quot;_blank
      
    
    </summary>
    
      <category term="2017/1" scheme="http://ktrmnm.github.io/blog/categories/2017-1/"/>
    
    
      <category term="個人用メモ" scheme="http://ktrmnm.github.io/blog/tags/%E5%80%8B%E4%BA%BA%E7%94%A8%E3%83%A1%E3%83%A2/"/>
    
  </entry>
  
  <entry>
    <title>Watanabe (2009) 本におけるカラテオドリ集合</title>
    <link href="http://ktrmnm.github.io/blog/2016/09/10/201609-caratheodory-family/"/>
    <id>http://ktrmnm.github.io/blog/2016/09/10/201609-caratheodory-family/</id>
    <published>2016-09-10T11:09:51.000Z</published>
    <updated>2020-03-01T09:20:31.231Z</updated>
    
    <content type="html"><![CDATA[<p>Algebraic Geometry and Statistical Learning Theory [W09] という本を輪読している。独自色の強い記法が使われていたりするので、自分の手持ちの知識にキャストする作業でそれなりに骨が折れる。</p><p>[W09] Watanabe. <a href="http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521864671" target="_blank" rel="noopener">Algebraic Geometry and Statistical Learning Theory</a>. Cambridge University Press, 2009.</p><p>大変だった部分を随時メモしていく。</p><a id="more"></a><p>5章における経験過程の定義はこのような感じである。たいへん複雑である。</p><p><strong> 定義： 経験過程 ([W09], Def 5.6) </strong><br>下の条件が満たされるとき、$\psi_n$ を経験過程ということにする。</p><ol><li>$X_1, X_2, \ldots, X_n \in \mathbb{R}^n$ は i.i.d. 確率変数とする。<ul><li>$X_i$ の確率密度は $q(x)$ とする。</li></ul></li><li>可測関数 $f: \mathbb{R}^n \times W \to \mathbb{R}$ について、<ul><li>$W \subset \mathbb{R}^n$ は開集合である。</li><li>$w \mapsto f(\cdot, w)$ は $L^p(q)$-値解析関数である ($p \geq 2$)。ただし、$L^p(q)$-値解析関数とは、各 $w^*$ について、ある近傍 $w^* \in U$ と $L^p(q)$ 値の係数 ${ a_\alpha (x) \in L^p(q) }$ が存在して、級数<br>$$<br>f(x, w) = \sum_{\alpha \in \mathbb{N}^d} a_\alpha (x) (w - w^*)^\alpha<br>$$<br>が $w \in U$ では $L^p$ 距離の意味で収束していることをいう。</li><li>各 $w \in W$ に対して $\mathbb{E}_X [ f(X, w)^2] &lt; \infty$.</li></ul></li><li>コンパクト集合 $K \subset W$ があって、<br>$$<br>\psi_n (w) = \frac{1}{\sqrt{n}} \sum_{i=1}^n [ f(X_i, w) - \mathbb{E}_X[ f(X, w)] ]<br>$$<br>は $C(K)$-値の確率変数となる。</li></ol><p>1は通常の仮定だと思う。<br>今回は、もともと「$X$ の真の分布がモデルに入っている」という問題を考えているので、密度 $q$ もある。</p><p>2はこの本独自の仮定である。<br>「$L^p$-値の解析関数」というのは不思議だが、別のところで $K(w) = \mathbb{E}_X[f(X, w)]$ の解析関数としての性質をもとに議論をすすめるときに、$f$ の方の話も整合的になるようにしているらしい。</p><p>ただし、超細かいことだが、本にあるように $f(\cdot, w)$ をBanach空間としての $L^p$ の元だと思ってしまうと $f(X_i, w)$ の値の意味がなくなってしまうので、Banach spaceとかnormといった記述はここでは削除するべきだと思う。しかし、具体例を考えている限りでは自分が心配しているような変なことは起きないようにも見える。そのあたりは日本語で先に出ている本 [W06] の方が余計なことが書いてない分親切だと思う。</p><p>[W06] 渡辺. <a href="http://www.morikita.co.jp/books/book/1905" target="_blank" rel="noopener">代数幾何と学習理論</a>．森北出版，2006.</p><p>3では、w は W ではなくて少し小さいコンパクト集合の上でだけ考えている。<br>おそらくこの部分が経験過程的には若干重要なのだと思われる。この本で出てくる「$\psi_n$ がGaussian processに法則収束する」という主張を示すときに、内部では<br>$$<br>\sup_{ w } \psi_n (w, X^n)<br>$$<br>をはじめとして、確率変数のあつまりを添字 w に関して sup を取るという操作がたくさん出てくるはずである。確率変数の非加算個のsupは確率変数になるとは限らないが、そういう可測性の問題はできればまとめて回避したい。$\psi_n(w, X^n)$ が添字に関して連続で、添字自体は完備可分というふうにすれば、supをとるときにcountable dense setをとってくればよいので問題が起きない。このような添字をとることができる集合を、[SC08] ではカラテオドリ集合と呼んでいる。</p><p>[SC08] Steinwart and Christmann. Support Vector Machines. Springer, 2008.</p><p>よくわかっていないが、解析性に関する性質を調べるときは $W$ が開集合の方が嬉しいのに対し、経験過程関係の性質は添字が完備可分じゃないと嬉しくないので、定義の2と3でこのようなズレが生じている気がする。</p><p>他にも、普通の有限次元の中心極限定理の主張でモーメントに関する条件が若干足りなかったりして落とし穴がある。知らないとわからない類の行間が多いので、学部生とかが輪読するのはつらそうだなという感想も少しある。一方、がんばって読んでいると稀に「これって普通に計算できたんだ」という感じの学びがあって面白い。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Algebraic Geometry and Statistical Learning Theory [W09] という本を輪読している。独自色の強い記法が使われていたりするので、自分の手持ちの知識にキャストする作業でそれなりに骨が折れる。&lt;/p&gt;
&lt;p&gt;[W09] Watanabe. &lt;a href=&quot;http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521864671&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Algebraic Geometry and Statistical Learning Theory&lt;/a&gt;. Cambridge University Press, 2009.&lt;/p&gt;
&lt;p&gt;大変だった部分を随時メモしていく。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/9" scheme="http://ktrmnm.github.io/blog/categories/2016-9/"/>
    
    
      <category term="学習理論" scheme="http://ktrmnm.github.io/blog/tags/%E5%AD%A6%E7%BF%92%E7%90%86%E8%AB%96/"/>
    
      <category term="経験過程論" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%8C%E9%A8%93%E9%81%8E%E7%A8%8B%E8%AB%96/"/>
    
      <category term="個人用メモ" scheme="http://ktrmnm.github.io/blog/tags/%E5%80%8B%E4%BA%BA%E7%94%A8%E3%83%A1%E3%83%A2/"/>
    
  </entry>
  
  <entry>
    <title>Langevin Monte Carlo法には棄却が必要か</title>
    <link href="http://ktrmnm.github.io/blog/2016/08/25/201608-lmc/"/>
    <id>http://ktrmnm.github.io/blog/2016/08/25/201608-lmc/</id>
    <published>2016-08-24T22:42:16.000Z</published>
    <updated>2020-03-01T09:20:31.196Z</updated>
    
    <content type="html"><![CDATA[<p>機械学習系のベイズっぽい論文を読んでいると、SGLD [WT11] やSGRLD [PT13] といった文字列を見ることがあります。これらが何かというとマルコフ連鎖モンテカルロ法 (MCMC) の一種で、正規化定数がわからない高次元の確率分布からのサンプリングを得たい場合などに使われます。</p><p>アルゴリズムの位置づけとしては、</p><ul><li>Langevin Monte Carlo (LMC) とか Langevin Dynamics などという名前で呼ばれている既存アルゴリズムがまずあり、</li><li>それに伴う勾配計算をサブサンプリングを利用して簡略化したもの<br>という感じです。勾配降下法 (GD) を確率的勾配降下法 (SGD) に拡張することにインスパイアされているのだったと思います。</li></ul><p>LMCのモチベーションとしてよく言われるのは、LMCでは (Metropolis–Hastings法に見られるような) 棄却ステップが必要ないということです。MHは、提案分布がうまく選べていなかったりすると棄却がたくさん発生してしまうことが知られていて、サンプリングに無駄な時間がかかってしまいます。MHの採択確率を（ほとんど）1にするというのは全ベイジアンの夢ですが、ある意味それを達成しているのがLMC系のアルゴリズムです。実際に、SGLDの元論文 [WT11] などでは、「棄却率を低くしたい」という動機がかなり強調して書いてあったりします。</p><p>動機だけを聞くとLMCは棄却が要らないという誤解が生じる可能性があるのですが、<strong>残念ながらそういうわけではない</strong> です。実際には、見た目上は同じアルゴリズムでも、サンプルを得たい分布の性質によって棄却が必要な場合とそうでない場合が存在します（ただし、その理論的な境界線をひとことで説明するのは難しい模様です）。</p><p>上のような知識を何度か論文で見かけたことはあったのですが、棄却せずに強行突破すると何が起きてしまうか正直よくわかってなかったです。<br>なので実際にやってみたというのが本記事の趣旨です。</p><a id="more"></a><h1 id="LMC"><a href="#LMC" class="headerlink" title="LMC"></a>LMC</h1><p>LMCの概要をラフに説明します。</p><p>$U(\theta)$ を $\mathbb{R}^d$ 上のある関数として、$\exp(-U)$ に比例した密度をもつ分布からのサンプルが欲しいとします。<br>このとき、<br>$$<br>\theta_{k + 1} = \theta_{k} - h \nabla U(\theta_k) + \sqrt{2h} \xi_{k+1}<br>\tag{1}<br>$$<br>という更新式によって $\theta_k$ を得るアルゴリズムをLangevin Monte Carlo法といいます。ただし $h &gt; 0$ はステップ幅で、簡単のため固定とします。$\xi_{k+1} \sim N(0, I)$ は $d$ 次元の標準正規分布に独立に従う確率変数の実現とします。「$U$ の勾配方向に $h$ だけ降りてから分散 $2h$ の正規ノイズで摂動する」という感じです。</p><p>例えば、ベイズの事後分布からのサンプリングを行いたいときは、<br>$$<br>U(\theta) = - \log p(\theta) - \sum_{i=1}^n \log p(x_i | \theta)<br>$$<br>のようなポテンシャルを考えればよいです。</p><p>理論的な背景としては、拡散過程<br>$$<br>\dd X_t = - \nabla U(X_t) \dd t + \sqrt{2} \dd W_t<br>\tag{2}<br>$$<br>の定常分布が $\pi(\theta) \propto \exp(-U(\theta))$ だということが知られているので、これを離散化 (Euler–Maruyama近似) したものがLMC法に相当します。</p><p>ただし、$U$ がどういう関数かによって</p><ul><li>(2) が定常分布を持たない</li><li>(2) は定常分布を持つが、その離散化 (1) が定常分布を持たない</li></ul><p>というケースが発生し、アルゴリズムがうまく動かない場合があります。それを実験で確かめたいです。</p><h1 id="うまく動く場合-t分布"><a href="#うまく動く場合-t分布" class="headerlink" title="うまく動く場合 (t分布)"></a>うまく動く場合 (t分布)</h1><p>1次元で実験します。自由度1の<a href="https://ja.wikipedia.org/wiki/T分布" target="_blank" rel="noopener">Studentのt分布</a> の密度関数を $f$ とすると<br>$$<br>U(x) = - \log f(x) = \log (1 + t^2) + const.<br>$$<br>と書けます。これを (1) 式に突っ込んでシミュレーションを回すとt分布からのサンプルが得られるはずです。</p><p>やってみるとこんな感じになります。左が生成されたパス、右がサンプルのヒストグラムです。うまくいっている気がします。</p><img src="/blog/2016/08/25/201608-lmc/t_dist.png" title="t分布に対するLMC"><h1 id="うまく動かない場合1"><a href="#うまく動かない場合1" class="headerlink" title="うまく動かない場合1"></a>うまく動かない場合1</h1><p>$$<br>\pi_{1/2} (x) = \frac{1}{4} \exp(- \sqrt{|x|})<br>$$<br>という分布を考えます。Laplace分布よりもっと裾が重い分布になります。</p><p>この分布に対して何も考えずにLMCを動かしてみると、見事にパスが発散します。</p><img src="/blog/2016/08/25/201608-lmc/nonergodic.png"><p>実は、この分布に形式的に対応する $U = -\log \pi_{1/2}$ を考えると、実は (2) の連続時間の確率過程すら定常分布を持たないことがわかります。こういうときはLMC系の手法を諦める事案だと思われます。</p><h1 id="うまく動かない場合2"><a href="#うまく動かない場合2" class="headerlink" title="うまく動かない場合2"></a>うまく動かない場合2</h1><p>さらに、もうちょっと微妙な、できそうなのにできないケースがあります。</p><p>$$<br>\pi_4 (x) = \frac{\exp(- x^4)}{2 \Gamma(5/4)}<br>$$<br>という分布を考えます。正規分布よりも裾が軽い分布になります。そのまま (1) 式に突っ込むのであれば、 $\nabla \log U(x) = -4 x^3$ とすればよいはずです。</p><p>この場合は (2) の確率過程は定常分布を持ち、それは $\pi_4$ に一致します。ですので、LMCも動いて欲しい気がします。</p><p>ところが実際にやってみると、どのようにステップ幅を設定しても、最初はうまくいっているかと思いきや途中でいきなり発散して終わります。<br><img src="/blog/2016/08/25/201608-lmc/transient.png"></p><p>実はこのケースでは、Euler–Maruyama法がエルゴード性を持たない (=収束しない) ということが理論的に示唆されています [RT96]。 数学的な条件としては、$\nabla U$ がLipschitzでないことがおそらく問題になっています。</p><h1 id="棄却ステップの導入"><a href="#棄却ステップの導入" class="headerlink" title="棄却ステップの導入"></a>棄却ステップの導入</h1><p>Metropolis Adjusted Langevin Algorithm (MALA) というアルゴリズムがあります。提案分布を (1) で定義した上で、<a href="https://ja.wikipedia.org/wiki/メトロポリス・ヘイスティングス法" target="_blank" rel="noopener">Metropolis–Hastings</a> と同じような棄却ステップを導入します。詳細は<a href="https://en.wikipedia.org/wiki/Metropolis-adjusted_Langevin_algorithm" target="_blank" rel="noopener">Wikipedia</a>や元論文 [RT96]、本 [RC10] などに載っています。</p><p>こちらのアルゴリズムを上の $\pi_4 (x)$ に対して導入してみると、パスが途中で発散することはなく、さらに目的の分布に近いヒストグラムがちゃんと得られているように見えます。ただしステップ幅を大きく取りすぎると採択率が下がり、計算が全く終わらなくなります。</p><img src="/blog/2016/08/25/201608-lmc/mala_beta4.png"><h1 id="PDF版"><a href="#PDF版" class="headerlink" title="PDF版"></a>PDF版</h1><p><a href="201608_mala.pdf">もうちょっと詳しく書いたPDF</a>を置いときます。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[WT11] M. Welling and Y. W. Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics. In ICML, 2011.<br>[PT13] S. Patterson and Y. W. Teh. Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex. In NIPS, 2013.<br>[RT96] G. O. Robert and R. L. Tweedie. Exponential convergence of Langevin distributions and their discrete<br>approximations. Bernoulli, 2(4):341–363, 1996.<br>[RC10] C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer, 2010.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;機械学習系のベイズっぽい論文を読んでいると、SGLD [WT11] やSGRLD [PT13] といった文字列を見ることがあります。これらが何かというとマルコフ連鎖モンテカルロ法 (MCMC) の一種で、正規化定数がわからない高次元の確率分布からのサンプリングを得たい場合などに使われます。&lt;/p&gt;
&lt;p&gt;アルゴリズムの位置づけとしては、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Langevin Monte Carlo (LMC) とか Langevin Dynamics などという名前で呼ばれている既存アルゴリズムがまずあり、&lt;/li&gt;
&lt;li&gt;それに伴う勾配計算をサブサンプリングを利用して簡略化したもの&lt;br&gt;という感じです。勾配降下法 (GD) を確率的勾配降下法 (SGD) に拡張することにインスパイアされているのだったと思います。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LMCのモチベーションとしてよく言われるのは、LMCでは (Metropolis–Hastings法に見られるような) 棄却ステップが必要ないということです。MHは、提案分布がうまく選べていなかったりすると棄却がたくさん発生してしまうことが知られていて、サンプリングに無駄な時間がかかってしまいます。MHの採択確率を（ほとんど）1にするというのは全ベイジアンの夢ですが、ある意味それを達成しているのがLMC系のアルゴリズムです。実際に、SGLDの元論文 [WT11] などでは、「棄却率を低くしたい」という動機がかなり強調して書いてあったりします。&lt;/p&gt;
&lt;p&gt;動機だけを聞くとLMCは棄却が要らないという誤解が生じる可能性があるのですが、&lt;strong&gt;残念ながらそういうわけではない&lt;/strong&gt; です。実際には、見た目上は同じアルゴリズムでも、サンプルを得たい分布の性質によって棄却が必要な場合とそうでない場合が存在します（ただし、その理論的な境界線をひとことで説明するのは難しい模様です）。&lt;/p&gt;
&lt;p&gt;上のような知識を何度か論文で見かけたことはあったのですが、棄却せずに強行突破すると何が起きてしまうか正直よくわかってなかったです。&lt;br&gt;なので実際にやってみたというのが本記事の趣旨です。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/8" scheme="http://ktrmnm.github.io/blog/categories/2016-8/"/>
    
    
      <category term="統計学" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%B1%E8%A8%88%E5%AD%A6/"/>
    
      <category term="機械学習" scheme="http://ktrmnm.github.io/blog/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
  </entry>
  
  <entry>
    <title>火曜日に生まれた男の子の話</title>
    <link href="http://ktrmnm.github.io/blog/2016/05/16/201605-twoboys/"/>
    <id>http://ktrmnm.github.io/blog/2016/05/16/201605-twoboys/</id>
    <published>2016-05-15T21:48:14.000Z</published>
    <updated>2020-03-01T09:20:31.192Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Twitterで見かけた問題"><a href="#Twitterで見かけた問題" class="headerlink" title="Twitterで見かけた問題"></a>Twitterで見かけた問題</h1><p>先日、こんな問題を見かけました ([1], 元ツイートは2010年)。</p><p><strong>“子どもが二人いる。（少なくとも）一人は男で火曜日に生まれた。二人とも男である確率は？（「火曜日に」を聞かなかった場合の確率も求めてください）”</strong></p><p>条件つき確率の問題でして、個人的にはいい問題だなーと感じました。</p><p>で、率直にいうと答えは</p><ul><li>「火曜日に」という情報を聞かなかった場合は 1/3</li><li>「火曜日に」という情報を聞いた場合は 13/27 (=0.48148…)</li></ul><p>です。</p><h1 id="図を見て3秒で理解する"><a href="#図を見て3秒で理解する" class="headerlink" title="図を見て3秒で理解する"></a>図を見て3秒で理解する</h1><p>ところが、とくに13/27という数字は、仮に条件つき確率の定義を知識として知っていたとしても、全く自明でない印象を受けてしまいます。<br>13とか27とかマジで？という感じ。</p><p>実際に計算して確認しようとすると3分くらいかかるのですが、願わくばもっと短時間で、何が起きているのか理解したいです。3秒くらいで。</p><p>というわけで、3秒で理解するための図を作りました。こちらです。</p><img src="/blog/2016/05/16/201605-twoboys/twoboys_3.png" title="条件つき確率を3秒で理解する図"><p>図では、AさんとBさんの性別と誕生日の曜日をタテヨコに並べてあります。2人分の性別と誕生日の組み合わせなので、14 * 14 = 196マスあります。<br>今、「一方は火曜日に生まれた男である」という情報を聞いたので、そうでないマスを黒く塗りつぶすと27マスだけ残ります。その中で、二人とも男であるのは赤く塗った13マスなので、13/27という数字が出てきます。</p><a id="more"></a><h2 id="補足1-もっとレアな情報を聞いた場合"><a href="#補足1-もっとレアな情報を聞いた場合" class="headerlink" title="補足1: もっとレアな情報を聞いた場合"></a>補足1: もっとレアな情報を聞いた場合</h2><p>「AさんかBさんは男」ではなくて、「Aさんは男」という情報を聞いた場合に、2人とも男である確率は1/2です。どちらかを名指しして性別を聞くと、2人とも男であるかどうかは名指ししていないほうの性別で決まるためです。</p><p>ここで、性別のほかの追加情報が「生まれた曜日」ではなくて、もっとレアな情報を教えてもらえる場合を考えます。</p><p>例えば、1年366日に均等に子どもが生まれるとして、「片方が1月1日生まれの男」という情報を聞いたとします。すると、2人とも男である確率は731/1463です。731/1463=0.499658…なので、ほとんど1/2に近い値です。</p><p>つまり、追加情報としてレアな情報を聞くと、1/2に限りなく近くなると言えます。</p><p>もうちょっと極端にするとわかりやすいです。<br>「2人の人間がいて、少なくとも一方は内閣総理大臣経験者で男である」とか言われた場合、2人とも男である確率はだいたい1/2な気がします。なぜなら、総理大臣などという激レア人材が含まれているという情報はほとんど特定の人物を名指ししているようなもので、2人とも男かどうかは残りの一方の（おそらく総理大臣ではない）人の性別で決まる気がします。</p><h2 id="補足2-定義どおりの計算"><a href="#補足2-定義どおりの計算" class="headerlink" title="補足2: 定義どおりの計算"></a>補足2: 定義どおりの計算</h2><p>上の問題の表現だと何を計算すべきかはっきりしない可能性もあります。なので、一応もう少し厳密な感じにリフレーズしておきます：</p><p>2人の子供A, Bがいるとして、性別がわからないとする。次の情報が与えられたとき、AもBも男であるという事象の条件つき確率を求めよ。</p><ul><li>AとBの少なくとも一方は男である。</li><li>AとBの少なくとも一方は火曜日に生まれた男である。<br>ただし、この世界では男の子は1/2の確率で生まれてくるとし、子供は全ての曜日において等確率で生まれてくるものとする。</li></ul><p>条件つき確率を定義どおりに書くと、<br>$$<br>\Pr(2人とも男 \mid 火曜日に生まれた男がいる) = \frac{\Pr(2人とも男で、火曜日に生まれた男がいる)}{\Pr(火曜日に生まれた男がいる)}<br>$$<br>なのであって、<br>$$<br>\begin{align}<br>&amp; \Pr(火曜日に生まれた男がいる) \\<br>= &amp; \Pr(Aが火曜日に生まれた男) + \Pr(Bが火曜日に生まれた男) -\Pr(AもBも火曜日に生まれた男) \\<br>= &amp; \frac{1}{14} + \frac{1}{14} - \frac{1}{14^2}<br>= \frac{27}{196}<br>\end{align}<br>$$<br>かつ<br>$$<br>\begin{align}<br>&amp; \Pr(2人とも男で、かつ火曜日に生まれた男がいる)\\<br>= &amp;\Pr(Aが火曜日に生まれた男で、Bは男) + \Pr(Aが男で、Bは火曜日に生まれた男)\\<br>&amp; - \Pr(AもBも火曜日に生まれた男) \\<br>= &amp; \frac{1}{14} \cdot \frac{1}{2} + \frac{1}{2} \cdot \frac{1}{14} - \frac{1}{14^2}<br>= \frac{13}{196}<br>\end{align}<br>$$<br>であるから、求めたい条件つき確率は確かに<br>$$<br>\frac{13/196}{27/196} = \frac{13}{27}<br>$$<br>となっています。</p><p>[1] <a href="https://twitter.com/h_okumura/status/14947083781" target="_blank" rel="noopener">@h_okumura先生のツイート</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Twitterで見かけた問題&quot;&gt;&lt;a href=&quot;#Twitterで見かけた問題&quot; class=&quot;headerlink&quot; title=&quot;Twitterで見かけた問題&quot;&gt;&lt;/a&gt;Twitterで見かけた問題&lt;/h1&gt;&lt;p&gt;先日、こんな問題を見かけました ([1], 元ツイートは2010年)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“子どもが二人いる。（少なくとも）一人は男で火曜日に生まれた。二人とも男である確率は？（「火曜日に」を聞かなかった場合の確率も求めてください）”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;条件つき確率の問題でして、個人的にはいい問題だなーと感じました。&lt;/p&gt;
&lt;p&gt;で、率直にいうと答えは&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「火曜日に」という情報を聞かなかった場合は 1/3&lt;/li&gt;
&lt;li&gt;「火曜日に」という情報を聞いた場合は 13/27 (=0.48148…)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;です。&lt;/p&gt;
&lt;h1 id=&quot;図を見て3秒で理解する&quot;&gt;&lt;a href=&quot;#図を見て3秒で理解する&quot; class=&quot;headerlink&quot; title=&quot;図を見て3秒で理解する&quot;&gt;&lt;/a&gt;図を見て3秒で理解する&lt;/h1&gt;&lt;p&gt;ところが、とくに13/27という数字は、仮に条件つき確率の定義を知識として知っていたとしても、全く自明でない印象を受けてしまいます。&lt;br&gt;13とか27とかマジで？という感じ。&lt;/p&gt;
&lt;p&gt;実際に計算して確認しようとすると3分くらいかかるのですが、願わくばもっと短時間で、何が起きているのか理解したいです。3秒くらいで。&lt;/p&gt;
&lt;p&gt;というわけで、3秒で理解するための図を作りました。こちらです。&lt;/p&gt;
&lt;img src=&quot;/blog/2016/05/16/201605-twoboys/twoboys_3.png&quot; title=&quot;条件つき確率を3秒で理解する図&quot;&gt;
&lt;p&gt;図では、AさんとBさんの性別と誕生日の曜日をタテヨコに並べてあります。2人分の性別と誕生日の組み合わせなので、14 * 14 = 196マスあります。&lt;br&gt;今、「一方は火曜日に生まれた男である」という情報を聞いたので、そうでないマスを黒く塗りつぶすと27マスだけ残ります。その中で、二人とも男であるのは赤く塗った13マスなので、13/27という数字が出てきます。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/5" scheme="http://ktrmnm.github.io/blog/categories/2016-5/"/>
    
    
      <category term="確率論" scheme="http://ktrmnm.github.io/blog/tags/%E7%A2%BA%E7%8E%87%E8%AB%96/"/>
    
  </entry>
  
  <entry>
    <title>輸送不等式から集中不等式を出す</title>
    <link href="http://ktrmnm.github.io/blog/2016/04/24/201604-transport-ineq-2/"/>
    <id>http://ktrmnm.github.io/blog/2016/04/24/201604-transport-ineq-2/</id>
    <published>2016-04-24T11:09:47.000Z</published>
    <updated>2020-03-01T09:20:31.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>Wasserstein距離がKLダイバージェンスで抑えられるという不等式のことを輸送不等式というのでした。例えば距離空間$(X, d)$上の確率測度$\mu$が$T_1(C)$を満たすというのは、任意の確率測度$\nu$に対して<br>$$<br>W_1(\mu, \nu) \leq \sqrt{C D_{KL} (\mu, \nu)}<br>\tag{1}<br>$$<br>が成り立つことをいいます。</p><p>$f: X \to \mathbb{R}$がLipschitz関数のとき、<br>$$<br>\forall t &gt; 0, \quad \Pr [ f - \mathbb{E}f \geq t] \leq \exp \left( - \frac{C t^2}{2 \lVert f \rVert_{Lip}^2} \right)<br>\tag{2}<br>$$<br>が成り立つという性質を考えます。言葉でいえば「すべてのLipschitz関数の像がsub-Gaussianのように振る舞う」ということです。このような性質をGaussian concentrationと呼びます。</p><p>実は、(1)ならば(2)が成り立ちます。</p><h2 id="機械学習系分野ではどう役立っているか"><a href="#機械学習系分野ではどう役立っているか" class="headerlink" title="機械学習系分野ではどう役立っているか"></a>機械学習系分野ではどう役立っているか</h2><p>学習理論やランダム行列論などでは、Gaussian concentrationはとてもありがたい性質です。最終的なアプリケーションで欲しいのは、あくまで(2)の形の集中不等式なのですが、そうだとしても(1)の形で集中不等式の情報を保持していた方が何かと便利な場合があります。</p><p>例えば、学習理論では、独立同分布に従うデータについての対数尤度や経験リスクがどう振る舞うかということに興味があるわけですが、要素技術としては「単体で(2)を満たすような確率分布の$n$個の直積が再び(2)を満たすかどうか」を考える必要が出てきます。そのとき、少なくとも(1)の形の不等式は直積操作で保存されるということがわかっているので都合が良いです。集中不等式界隈（？）では、こういう性質を不等式のテンソル化 (tensorization) と呼びます。</p><a id="more"></a><h1 id="T1不等式から集中不等式が出ること"><a href="#T1不等式から集中不等式が出ること" class="headerlink" title="T1不等式から集中不等式が出ること"></a>T1不等式から集中不等式が出ること</h1><p>$(X, d)$をポーランド空間とする。$\mu$を$X$上の (Borel) 確率測度とする。</p><p><strong>命題</strong></p><p>$\mu$が(1)を満たすならば、(2)も成り立つ。</p><p><strong>証明</strong></p><p><a href="http://ktrmnm.github.io/blog/2016/04/08/201604-transport-ineq/">こちら</a>に書いた、「輸送不等式の双対」を使うとすぐに出る。（双対形がそのままモーメント母関数のバウンドになっている）</p><p>$f$が$1$-Lipschitzの場合に示す。一般の場合は$\lVert f \rVert_{Lip}$でスケールすればよい。</p><p>$\mu$が$T_1(C)$を満たすことと、任意の有界連続関数$f$について<br>$$<br>\mathbb{E} \exp(\lambda \inf_{y \in X} [f(y) + d(x,y)]) \leq \exp \left( \frac{\lambda^2}{2C} + \lambda \mathbb{E}f \right)<br>\tag{3}<br>$$<br>が成り立つことは同値である。<br>$f$は$1$-Lipschitzなので、<br>$$<br>\inf_{y \in X} [f(y) + d(x,y)] = f(x)<br>$$<br>である。(3)から、<br>$$<br>\mathbb{E} \exp(\lambda [f - \mathbb{E}f]) \leq \exp(\lambda^2/2C).<br>$$</p><p>Chebyshevの不等式より<br>$$<br>\Pr[ f- \mathbb{E}f \geq t] = \Pr[\exp(\lambda[f - \mathbb{E}f]) \geq e^{\lambda t}]<br>\leq \exp(- \lambda t + \lambda^2/2C).<br>$$<br>右辺を$\lambda$について最適化すると(2)が示せる。</p><h1 id="補足"><a href="#補足" class="headerlink" title="補足"></a>補足</h1><p>上の命題は[1] Theorem 22.10の一部で、以下が成り立つことは（定数部分を除いて）すべて同値だと言っています。</p><ul><li>T1不等式</li><li>T1不等式の双対</li><li>平均まわりのGaussian concentration</li><li>メジアンまわりのGaussian concentration</li><li>$\exp(a d(x_0, x)^2)$の可積分性</li></ul><p>そういえば、だいぶ前に集中不等式の本のゼミ用に作ったスライドがあります。輸送の話もちらっと書いているものの、今はもう少し理解しているような気がするので、時間があったらまた作り直したいなと。</p><p><iframe src="//www.slideshare.net/slideshow/embed_code/key/9RWCJ1qykrVkGE" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/kentarominami39/1-43984243" title="集中不等式のすすめ [集中不等式本読み会#1]" target="_blank">集中不等式のすすめ [集中不等式本読み会#1]</a> </strong> from <strong><a href="//www.slideshare.net/kentarominami39" target="_blank">Kentaro Minami</a></strong> </div></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] C. Villani. Optimal Transport: Old and New, Springer, 2009.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概要&quot;&gt;&lt;a href=&quot;#概要&quot; class=&quot;headerlink&quot; title=&quot;概要&quot;&gt;&lt;/a&gt;概要&lt;/h1&gt;&lt;p&gt;Wasserstein距離がKLダイバージェンスで抑えられるという不等式のことを輸送不等式というのでした。例えば距離空間$(X, d)$上の確率測度$\mu$が$T_1(C)$を満たすというのは、任意の確率測度$\nu$に対して&lt;br&gt;$$&lt;br&gt;W_1(\mu, \nu) \leq \sqrt{C D_{KL} (\mu, \nu)}&lt;br&gt;\tag{1}&lt;br&gt;$$&lt;br&gt;が成り立つことをいいます。&lt;/p&gt;
&lt;p&gt;$f: X \to \mathbb{R}$がLipschitz関数のとき、&lt;br&gt;$$&lt;br&gt;\forall t &amp;gt; 0, \quad \Pr [ f - \mathbb{E}f \geq t] \leq \exp \left( - \frac{C t^2}{2 \lVert f \rVert_{Lip}^2} \right)&lt;br&gt;\tag{2}&lt;br&gt;$$&lt;br&gt;が成り立つという性質を考えます。言葉でいえば「すべてのLipschitz関数の像がsub-Gaussianのように振る舞う」ということです。このような性質をGaussian concentrationと呼びます。&lt;/p&gt;
&lt;p&gt;実は、(1)ならば(2)が成り立ちます。&lt;/p&gt;
&lt;h2 id=&quot;機械学習系分野ではどう役立っているか&quot;&gt;&lt;a href=&quot;#機械学習系分野ではどう役立っているか&quot; class=&quot;headerlink&quot; title=&quot;機械学習系分野ではどう役立っているか&quot;&gt;&lt;/a&gt;機械学習系分野ではどう役立っているか&lt;/h2&gt;&lt;p&gt;学習理論やランダム行列論などでは、Gaussian concentrationはとてもありがたい性質です。最終的なアプリケーションで欲しいのは、あくまで(2)の形の集中不等式なのですが、そうだとしても(1)の形で集中不等式の情報を保持していた方が何かと便利な場合があります。&lt;/p&gt;
&lt;p&gt;例えば、学習理論では、独立同分布に従うデータについての対数尤度や経験リスクがどう振る舞うかということに興味があるわけですが、要素技術としては「単体で(2)を満たすような確率分布の$n$個の直積が再び(2)を満たすかどうか」を考える必要が出てきます。そのとき、少なくとも(1)の形の不等式は直積操作で保存されるということがわかっているので都合が良いです。集中不等式界隈（？）では、こういう性質を不等式のテンソル化 (tensorization) と呼びます。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/4" scheme="http://ktrmnm.github.io/blog/categories/2016-4/"/>
    
    
      <category term="確率論" scheme="http://ktrmnm.github.io/blog/tags/%E7%A2%BA%E7%8E%87%E8%AB%96/"/>
    
      <category term="最適輸送" scheme="http://ktrmnm.github.io/blog/tags/%E6%9C%80%E9%81%A9%E8%BC%B8%E9%80%81/"/>
    
  </entry>
  
  <entry>
    <title>Generic Chaining (3)</title>
    <link href="http://ktrmnm.github.io/blog/2016/04/12/201604-generic-chaining-3/"/>
    <id>http://ktrmnm.github.io/blog/2016/04/12/201604-generic-chaining-3/</id>
    <published>2016-04-12T11:22:56.000Z</published>
    <updated>2020-03-01T09:20:31.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>Generic chainingのタイトさを個人的に理解するためのノートの3つめ。</p><ul><li><a href="http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/">その1</a></li><li><a href="http://ktrmnm.github.io/blog/2016/03/25/20160325-generic-chaining-2/">その2</a></li></ul><p>実は、とてもわかりやすい資料[1]を発見したため、あまり自分でリライトする意味がなくなりつつある。でも一応自分の言葉でまとめておく。</p><p>$X_t$は平均0の$d$-sub-Gaussian processとする。つまり、増分がsub-Gaussianであるような確率過程とする：<br>$$<br>\Pr(| X_s - X_t| \geq u) \leq 2 \exp \left( - \frac{u^2}{2d(s,t)^2}\right).<br>\tag{1}<br>$$<br>下つきの添字がスペース上の都合で書きにくいときは$X_t = X(t)$とも書く。</p><p>特に、$X_t$がガウス過程のときは、距離$d$として、$X_t$から定まる内在的な距離<br>$$<br>d(s, t) = \sqrt{\mathbb{E}(X_t - X_t)^2}<br>$$<br>を用いればよい。</p><p>平均0なので、$t_0 \in T$を固定すれば<br>$$<br>\mathbb{E}\sup_t X(t) = \mathbb{E}\sup_t (X(t) - X(t_0))<br>$$<br>が成り立つ。左辺に興味がある場合も、右辺を考えた方が今は都合がよい。$Y = \sup_t (X(t) - X(t_0))$は非負なので、<br>$$<br>\mathbb{E} Y = \int_0^\infty \Pr(Y \geq u) \dd u<br>$$<br>が成り立つ。</p><a id="more"></a><h1 id="Generic-chainingによる上界"><a href="#Generic-chainingによる上界" class="headerlink" title="Generic chainingによる上界"></a>Generic chainingによる上界</h1><p>連鎖 (chaining) というのは次のような考え方であった。$T$の代表点の集合$T_n$の増加列をつくり、$T_n$の要素数が増大するペースと、近時の第$n$階層と$(n+1)$階層の間の分散が減るペースをコントロールする。分散と要素数がコントロールされたsub-Gaussian変数の最大値（の期待値）をバウンドする不等式を用いて、$|X(\pi_n(t)) - X(\pi_{n+1}(t))|$の最大値をまとめ上げることによって、目的の$|X(t)-X(t_0)|$の最大値をバウンドする（<a href="http://ktrmnm.github.io/blog/2016/03/25/20160325-generic-chaining-2/">前回</a>参照）。</p><p>上の操作をもっとシステマティックに整理したのがgeneric chainingによる上界と言える。<br>改善の余地があるとしたら、直感的には次の二点な気がする：</p><ul><li>もともとのchainingでは、$T_n$は$T$の$2^{-n}$-netになるようにとった。つまり、$T_n$の点はいわば等間隔に選んでいたが、冷静に考えると必ずしもそうである必要はない。$T$という空間の形状を考慮すると、最大に近い値をとりやすい領域とそうでない領域が発生している可能性がある。そういった$T$の偏りを考慮すると、実際に最大値をとりそうな領域の周辺で解像度を上げるべきかもしれない。</li><li>もとは階層ごとに最大不等式を使ってバウンドしていた。こうすると、階層ごとにチェーンをぶつ切りにして最大値を達成するような代表点の組をその都度選び直していることになるが、どうせならチェーンはつながったままにして、最大を考える作業は最後にまとめてやれば良い気がする。$\sum_n \sup_t$よりも$\sup_\t \sum_n$の方がおそらくましである（下の(4)式も参照）。</li></ul><p>というわけで、generic chainingでは、$T_n$の点の間隔を可変にして、$\sup_t$という評価を行う作業は最後まで遅延する。</p><p>以下で考える$T_n$は、$T_0 = \{ t_0 \}$であって、$T_0 \subset T_1 \subset \cdots \subset T$となるような列とする。<br>ただし、間隔を可変にしたとはいえ、要素数が一気に増えすぎるとunion boundが無意味になるという（若干技術的な）事情があるので、<br>$$<br>|T_n|\leq 2^{2^n}<br>$$<br>となるようにする。イメージとしては、$|T_{n + 1}| \approx |T_n|^2$というペースで要素数を増やす[1]。<br>$\gamma_2(T,d)$を次のように定義する：<br>$$<br>\gamma_2(T, d) := \inf \sup_{t \in T} \sum_{n=0}^\infty 2^{n/2} d(t, T_n)<br>$$<br>ここで、infは上のような$T_n$の全体にわたってとる。$d(t, T_n) = \min_{s \in T_n} d(t, s)$とする。</p><p><strong>定理</strong><br>普遍的な定数$C &gt; 0$が存在して、<br>$$<br>\mathbb{E}\sup_t X_t \leq C \gamma_2(T, d)<br>\tag{2}<br>$$<br>が成り立つ。</p><p>証明は省略するが、要は$T_n$を固定したときに<br>$$<br>\Pr( \sup_t (X(t) - X(t_0) &gt;  u \sum_{n=0}^\infty 2^{n/2} d(t, T_n)) \leq C \exp(-u^2)<br>$$<br>であることを言えばよいのであって、これはsub-Gaussian性(1)とunion boundから出てくる。</p><p>とはいえ、結局、”最適な” $T_n$の選び方をある程度特定してやらないことには(2)のタイト感はよくわからない。<br>一方で、前述のように$T_n$を等間隔にしたものがchainingであったから、chaining boundに相当するものは(2)から復元できる。</p><p><strong>エントロピー数</strong> $e_n(T)$を、<br>$$<br>e_n(T) := \inf_{T_n} \sup_t d(t, T_n)<br>\tag{3}<br>$$<br>と定義する。ただし、infは$|T_n| \leq 2^{2^n}$をみたすような有限集合全体にわたってとる。エントロピー数は、$\epsilon$-カバリングナンバーや$\epsilon$-パッキングナンバーの逆関数のようなもので、要素数を固定したときの$\epsilon$だと考えればよい。<br>(3)でinfを達成するような$T_n$を選ぶことによって、<br>$$<br>\gamma_2(T, d) \leq \sup_t \sum_{n=0}^\infty 2^{n/2} d(t, T_n) \leq \sum_{n=0}^\infty 2^{n/2} e_n(T)<br>\tag{4}<br>$$<br>がわかる。しかし、最右辺は、ある定数$C &gt; 0$が存在して<br>$$<br>\sum_{n=0}^\infty 2^{n/2} e_n(T) \leq C \int_0^\infty \sqrt{\log N(T, d, \epsilon)} \dd \epsilon<br>$$<br>であることがわかるから[2]、chaining boundが (up-to-constantで) 復元する。</p><h1 id="Generic-chainingによる下界"><a href="#Generic-chainingによる下界" class="headerlink" title="Generic chainingによる下界"></a>Generic chainingによる下界</h1><p>$X_t$はガウス過程であるとする。この場合はとくに、generic chainingによる<strong>下からの評価</strong>も成立する。</p><p><strong>定理 (Majorizing measure theorem)</strong><br>$X_t$はガウス過程とし、$d$は$X_t$からきまる$T$上の擬距離とする。普遍的な定数$c &gt; 0$が存在して、<br>$$<br>\mathbb{E}\sup_t X_t \geq c \gamma_2(T, d)<br>$$<br>が成り立つ。</p><p>少々どうでもいいんですが、なぜmajorizing “measure”という名前なのかというと、$\gamma_2$と本質的に同じものを代表点$T_n$ではなくて$T$上の測度を使って定式化することができ、そちらが先に出てきたという歴史的経緯によるものらしい。”Majorizing measures without measures”という（一体何を言ってるんだという感じのタイトルの）論文が存在するあたり、若干その雰囲気がうかがえる。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>このノートでは確率過程のsupについて次のことを書いた:</p><ul><li>有限個のsub-Gaussian変数の最大不等式 ($\sqrt{\log N}$)</li><li>sub-Gaussian processのchaining bound ($\int \sqrt{\log N(T, d, \epsilon)} \dd \epsilon$)</li><li>generic chaining bound (上界 &amp; ガウス過程の下界)</li></ul><p>他にもchaining boundがタイトでなくなる具体例とか、下界が成り立つ理由を書こうと思ったものの、力尽きたのでやめておく。[2]が専門書です。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] J. R. Lee. Notes on Gaussian processes and majorizing measures (<a href="https://homes.cs.washington.edu/~jrl/mm.pdf" target="_blank" rel="noopener">PDF</a>)<br>[2] M. Talagrand. Upper and Lower bounds for Stochastic Processes, Springer, 2014.<br>[3] M. Talagrand. Majorizing Measures without Measures, The Annals of Probability, 29(1):411–417, 2001.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前提&quot;&gt;&lt;a href=&quot;#前提&quot; class=&quot;headerlink&quot; title=&quot;前提&quot;&gt;&lt;/a&gt;前提&lt;/h1&gt;&lt;p&gt;Generic chainingのタイトさを個人的に理解するためのノートの3つめ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/&quot;&gt;その1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ktrmnm.github.io/blog/2016/03/25/20160325-generic-chaining-2/&quot;&gt;その2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;実は、とてもわかりやすい資料[1]を発見したため、あまり自分でリライトする意味がなくなりつつある。でも一応自分の言葉でまとめておく。&lt;/p&gt;
&lt;p&gt;$X_t$は平均0の$d$-sub-Gaussian processとする。つまり、増分がsub-Gaussianであるような確率過程とする：&lt;br&gt;$$&lt;br&gt;\Pr(| X_s - X_t| \geq u) \leq 2 \exp \left( - \frac{u^2}{2d(s,t)^2}\right).&lt;br&gt;\tag{1}&lt;br&gt;$$&lt;br&gt;下つきの添字がスペース上の都合で書きにくいときは$X_t = X(t)$とも書く。&lt;/p&gt;
&lt;p&gt;特に、$X_t$がガウス過程のときは、距離$d$として、$X_t$から定まる内在的な距離&lt;br&gt;$$&lt;br&gt;d(s, t) = \sqrt{\mathbb{E}(X_t - X_t)^2}&lt;br&gt;$$&lt;br&gt;を用いればよい。&lt;/p&gt;
&lt;p&gt;平均0なので、$t_0 \in T$を固定すれば&lt;br&gt;$$&lt;br&gt;\mathbb{E}\sup_t X(t) = \mathbb{E}\sup_t (X(t) - X(t_0))&lt;br&gt;$$&lt;br&gt;が成り立つ。左辺に興味がある場合も、右辺を考えた方が今は都合がよい。$Y = \sup_t (X(t) - X(t_0))$は非負なので、&lt;br&gt;$$&lt;br&gt;\mathbb{E} Y = \int_0^\infty \Pr(Y \geq u) \dd u&lt;br&gt;$$&lt;br&gt;が成り立つ。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/4" scheme="http://ktrmnm.github.io/blog/categories/2016-4/"/>
    
    
      <category term="学習理論" scheme="http://ktrmnm.github.io/blog/tags/%E5%AD%A6%E7%BF%92%E7%90%86%E8%AB%96/"/>
    
      <category term="経験過程論" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%8C%E9%A8%93%E9%81%8E%E7%A8%8B%E8%AB%96/"/>
    
      <category term="確率論" scheme="http://ktrmnm.github.io/blog/tags/%E7%A2%BA%E7%8E%87%E8%AB%96/"/>
    
  </entry>
  
  <entry>
    <title>輸送不等式の双対</title>
    <link href="http://ktrmnm.github.io/blog/2016/04/08/201604-transport-ineq/"/>
    <id>http://ktrmnm.github.io/blog/2016/04/08/201604-transport-ineq/</id>
    <published>2016-04-07T15:00:00.000Z</published>
    <updated>2020-03-01T09:20:31.192Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ひとことまとめ"><a href="#ひとことまとめ" class="headerlink" title="ひとことまとめ"></a>ひとことまとめ</h1><p>輸送不等式の双対表現がおもしろかったので。</p><h1 id="輸送不等式"><a href="#輸送不等式" class="headerlink" title="輸送不等式"></a>輸送不等式</h1><p>最適輸送 (optimal transport) というジャンルがある。元々どういう問題なのかは[1]などに譲るとするが、最適輸送で出てくる色々なツールが、他の問題を考えるときにも色々と有益だということが知られていて、確率論の別のジャンルでもしばしば使われる。</p><p>$(X, d)$を距離空間とする。$\mu, \nu$を$X$上の (Borel) 確率測度とする。$X^2$上の確率測度$\pi$で、軸方向への周辺分布がそれぞれ$\mu$と$\nu$に等しいようなものを<strong>カップリング</strong>という。</p><p>カップリングは、「輸送計画」みたいなものに相当する。つまり、$X$という空間上にある$\mu$という山を切り崩して$\nu$という山に移し替えたい。どの部分を切り取ってどこに持っていくかということを表したものが$\pi$である。<br>ところが、山を切り崩して移動するというのをタダで行えるわけではない。$X$上の点$x_1$から$x_2$に荷物を運ぶのに、$x_1$と$x_2$の距離が遠いほど多くコストがかかるかかるという状況を考える。沖縄などの地域で通販の送料が無料にならなかったりするのはそういう理由だろう（沖縄に住んでいらっしゃる方はすみません）。例えば、単位体積を$x_1$から$x_2$に運ぶのに、$d^p(x_1, x_2)$円かかるとする。このとき、全体での輸送コストは<br>$$<br>\int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2)<br>$$<br>のと書ける。このコストを最小化するように輸送計画を設計しようというのが、最適輸送という問題である。</p><p>上の最小値を<br>$$<br>\inf_\pi \int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2)<br>$$<br>とする。実は、輸送するためのコストが最小限いくらかかるかで、確率測度のあいだの距離が測れる。実際、<br>$$<br>W_p(\mu, \nu) := \left( \inf_\pi \int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2) \right)^{1/p}<br>$$<br>は距離になるが、これを<a href="https://en.wikipedia.org/wiki/Wasserstein_metric" target="_blank" rel="noopener">Wasserstein距離</a>という（注1）。</p><p>$\mu$と$\nu$のKLダイバージェンスを$D(\mu, \nu)$と書く（定義は下）。この記事でいう輸送不等式というのは、次のようなものである：<br>任意の確率測度$\nu$に対して、不等式<br>$$<br>W_p^p(\mu, \nu) \leq \sqrt{C D(\mu, \nu)}<br>\tag{1}<br>$$<br>が成り立つとき、$\mu$は輸送不等式$T_p(C)$をみたすという。</p><a id="more"></a><p><a href="https://en.wikipedia.org/wiki/Pinsker%27s_inequality" target="_blank" rel="noopener">Pinskerの不等式</a>は輸送不等式の例になっている。というのも実は、<a href="https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures" target="_blank" rel="noopener">全変動距離</a>はハミング距離$d(x,y) = 1_{ x \neq y }$に対するWasserstein距離とみなせる。<br>$$<br>\lVert \mu - \nu \rVert_\mathrm{TV} = \sup |\mu(A) - \nu(A)| = \inf_\pi \int 1_{ x \neq y} \dd \pi(x,y)<br>$$<br>だから上の表記でいえばPinskerの不等式<br>$$<br>\lVert \mu - \nu \rVert_\mathrm{TV} \leq \sqrt{\frac{1}{2} D(\mu, \nu)}<br>$$<br>は$T_1(1/2)$ということになる。</p><p>$T_2(C)$にも有名な例がある。<br>$\mathbb{R}^n$に通常のEuclid距離を入れた空間を考える。$n$次元標準正規分布$\gamma_n$について、Talagrandの輸送不等式<br>$$<br>W_2^2(\nu, \gamma_n) \leq \sqrt{2 D(\nu, \gamma_n)}<br>$$<br>が成り立つことが知られている。上の表記でいうと、$\gamma_n$は$T_2(2)$をみたすということになる。</p><p>ところで、$T_p(C)$には双対表現というべき等価な不等式があって、それを導出するのに色々な双対が出てきておもしろい。</p><h1 id="いろんな双対"><a href="#いろんな双対" class="headerlink" title="いろんな双対"></a>いろんな双対</h1><p>最適輸送コストとKLダイバージェンスには、それぞれの文脈から出てきた双対公式がある。<br>世の中にはいろんな双対があるなあ（詠嘆）。</p><h2 id="Kantrovich双対性"><a href="#Kantrovich双対性" class="headerlink" title="Kantrovich双対性"></a>Kantrovich双対性</h2><p>$C_b(X)$を$X$上の有界連続関数の全体とする。<br>最適輸送コストについて、次のような等式が成り立つ。<br>$$<br>\begin{align}<br>W^p_p(\mu, \nu) &amp; = \inf_\pi \int_{X^2} d^p(x, y) \dd \pi(x, y) \\<br>&amp; = \sup \left \{<br>\int f(x) \dd \mu(x) + \int g(y) \dd \nu(y) :\; f, g \in C_b(X), \; f(x) + g(y) \leq d^p(x, y)<br>\right \}<br>\end{align}<br>\tag{2}<br>$$<br>これをKantrovich双対性という。最適化がわかる人向けにいうと、最適輸送問題の双対問題は<br>$$<br>\begin{align}<br>\max \quad &amp; \int f(x) \dd \mu(x) + \int g(y) \dd \nu(y) \\<br>s.t. \quad &amp; f(x) + g(y) \leq d^p(x, y)<br>\end{align}<br>$$<br>みたいなものに相当するらしく、しかも相補性が成り立つらしい。</p><h2 id="KLダイバージェンス"><a href="#KLダイバージェンス" class="headerlink" title="KLダイバージェンス"></a>KLダイバージェンス</h2><p>$\mu$と$\nu$のKLダイバージェンスを<br>$$<br>D(\mu, \nu) = \int \log \frac{\dd \mu}{\dd \nu} \dd \mu<br>$$<br>と定義する。ただし、$\mu \ll \nu$でないときは$+\infty$とする。KLダイバージェンスには次のような双対公式がある。<br>$$<br>\log \int \exp(f(x)) \dd \nu(x) = \sup_{\mu: \; \mu \ll \nu} \left( \int f(x) \dd \mu  - D(\mu, \nu) \right)<br>\tag{3}<br>$$<br>Donsker-Varadhanの変分公式ともいうらしい。ちなみに<a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods" target="_blank" rel="noopener">変分ベイズ</a>の原理とかはこれにとても近い。KLを最小化したければ双対表現を最小化すればいいじゃない、という発想。</p><p>また、今回は使わないが、<br>$$<br>D(\mu, \nu) = \sup_{f \in C_b(X)} \left \{<br>\int f(x) \dd\mu(x) - \log \int \exp(f(x)) \dd \nu(x)<br>\right \}<br>\tag{4}<br>$$<br>という双対公式も存在する[3]。</p><h2 id="ルジャンドル変換"><a href="#ルジャンドル変換" class="headerlink" title="ルジャンドル変換"></a>ルジャンドル変換</h2><p>道行く人に「あなたの好きな双対は何ですか」と聞いてまわったらFenchel双対はベスト5くらいに入るんじゃないか。</p><p>それはさておき、下でちょっと使うので、つまらない例だけれど復習しておく。<br>$x \geq 0$で定義された凸関数$h(x) = a x^2$ ($a &gt; 0$) の<a href="https://ja.wikipedia.org/wiki/ルジャンドル変換" target="_blank" rel="noopener">ルジャンドル変換</a>は</p><p>$$<br>h^{*}(y) = \max_{y \geq 0} (xy - h(x)) = \frac{y^2}{4a}<br>$$<br>である。<br>凸関数のルジャンドル変換のルジャンドル変換は元に戻る。<br>$$<br>h^{**}(x) = \max_{x \geq 0} (yx - h^*(y)) = ax^2 = h(x)<br>$$</p><h1 id="輸送不等式の双対"><a href="#輸送不等式の双対" class="headerlink" title="輸送不等式の双対"></a>輸送不等式の双対</h1><p>Kantrovich双対とKLダイバージェンスの双対とを合わせることで、輸送不等式の双対形が得られる。<br>もともと$T_p(C)$というのは「すべての確率測度についてhoge」という主張だったのだが、双対形のほうは「すべての有界連続関数についてpiyo」という主張になる。</p><p><strong>定理</strong><br>$\mu$が$T_p(C)$を満たすことは次のことと同値である：<br>任意の$f, g \in C_b(X)$ s.t. $f(x) + g(y) \leq d^p(x, y)$に対して、<br>$$<br>\forall t \geq 0, \quad \int \exp(tf(x)) \dd \mu(x)<br>\leq \exp \left( - t \int g(x)\dd \mu + \frac{Ct^2}{4} \right).<br>$$</p><p><strong>証明</strong><br>Kantrovich双対性(2)より、$T_p(C)$であることと、任意の$f, g \in C_b(X)$ s.t. $f(x) + g(y) \leq d^p(x, y)$および任意の$\nu$に対して、<br>$$<br>C^{-1}\left( \int f(x) \dd \nu(x) + \int g(y) \dd \mu(y) \right)^2 \leq D(\nu, \mu)<br>\tag{5}<br>$$<br>が成り立つことと同値である。<br>$h(x) = C^{-1}x^2$のルジャンドル変換を考えることにより、$h(x) = \sup_t (tx - Ct^2/4)$であるから、(5)は<br>$$<br>\forall t \geq 0, \int tf(x) \dd \nu(x) - D(\nu, \mu) \leq -\int tg(x) \dd \mu(x) + \frac{Ct^2}{4}<br>$$<br>と同値である。<br>Donsker-Varadhanの公式(4)より、左辺を$\nu$について最適化すると、<br>$$<br>\log \int \exp(tf(x))\dd \mu(x) \leq -\int tg(x) \dd \mu(x) + \frac{Ct^2}{4}<br>$$<br>であるから示された。</p><p>証明は[3]を参考にした。$p = 1, 2$の場合は[2]が初出とのこと。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Villani. Optimal Transport: Old and new, Springer, 2009.<br>[2] Bobkov and Götze. Exponential integrability and transportation cost related to logarithmic Sobolev inequalities, J. Fucnt. Anal., 163(1):1–28, 1999.<br>[3] Gozlan and Leonard. Transport inequalities. A survey, Markov Processes and Related Fields, 16(4):635–736, 2010.</p><p>(注1) Wasserstein距離は、他の距離的な尺度（total variation, KLダイバージェンス, etc.）と違って、$X$上の距離$d$の情報が確率測度間の距離に陽に反映されているということで、最近は機械学習の学会でもちらほら応用を見かける。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ひとことまとめ&quot;&gt;&lt;a href=&quot;#ひとことまとめ&quot; class=&quot;headerlink&quot; title=&quot;ひとことまとめ&quot;&gt;&lt;/a&gt;ひとことまとめ&lt;/h1&gt;&lt;p&gt;輸送不等式の双対表現がおもしろかったので。&lt;/p&gt;
&lt;h1 id=&quot;輸送不等式&quot;&gt;&lt;a href=&quot;#輸送不等式&quot; class=&quot;headerlink&quot; title=&quot;輸送不等式&quot;&gt;&lt;/a&gt;輸送不等式&lt;/h1&gt;&lt;p&gt;最適輸送 (optimal transport) というジャンルがある。元々どういう問題なのかは[1]などに譲るとするが、最適輸送で出てくる色々なツールが、他の問題を考えるときにも色々と有益だということが知られていて、確率論の別のジャンルでもしばしば使われる。&lt;/p&gt;
&lt;p&gt;$(X, d)$を距離空間とする。$\mu, \nu$を$X$上の (Borel) 確率測度とする。$X^2$上の確率測度$\pi$で、軸方向への周辺分布がそれぞれ$\mu$と$\nu$に等しいようなものを&lt;strong&gt;カップリング&lt;/strong&gt;という。&lt;/p&gt;
&lt;p&gt;カップリングは、「輸送計画」みたいなものに相当する。つまり、$X$という空間上にある$\mu$という山を切り崩して$\nu$という山に移し替えたい。どの部分を切り取ってどこに持っていくかということを表したものが$\pi$である。&lt;br&gt;ところが、山を切り崩して移動するというのをタダで行えるわけではない。$X$上の点$x_1$から$x_2$に荷物を運ぶのに、$x_1$と$x_2$の距離が遠いほど多くコストがかかるかかるという状況を考える。沖縄などの地域で通販の送料が無料にならなかったりするのはそういう理由だろう（沖縄に住んでいらっしゃる方はすみません）。例えば、単位体積を$x_1$から$x_2$に運ぶのに、$d^p(x_1, x_2)$円かかるとする。このとき、全体での輸送コストは&lt;br&gt;$$&lt;br&gt;\int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2)&lt;br&gt;$$&lt;br&gt;のと書ける。このコストを最小化するように輸送計画を設計しようというのが、最適輸送という問題である。&lt;/p&gt;
&lt;p&gt;上の最小値を&lt;br&gt;$$&lt;br&gt;\inf_\pi \int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2)&lt;br&gt;$$&lt;br&gt;とする。実は、輸送するためのコストが最小限いくらかかるかで、確率測度のあいだの距離が測れる。実際、&lt;br&gt;$$&lt;br&gt;W_p(\mu, \nu) := \left( \inf_\pi \int_{X^2} d^p(x_1, x_2) \dd \pi(x_1, x_2) \right)^{1/p}&lt;br&gt;$$&lt;br&gt;は距離になるが、これを&lt;a href=&quot;https://en.wikipedia.org/wiki/Wasserstein_metric&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Wasserstein距離&lt;/a&gt;という（注1）。&lt;/p&gt;
&lt;p&gt;$\mu$と$\nu$のKLダイバージェンスを$D(\mu, \nu)$と書く（定義は下）。この記事でいう輸送不等式というのは、次のようなものである：&lt;br&gt;任意の確率測度$\nu$に対して、不等式&lt;br&gt;$$&lt;br&gt;W_p^p(\mu, \nu) \leq \sqrt{C D(\mu, \nu)}&lt;br&gt;\tag{1}&lt;br&gt;$$&lt;br&gt;が成り立つとき、$\mu$は輸送不等式$T_p(C)$をみたすという。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/4" scheme="http://ktrmnm.github.io/blog/categories/2016-4/"/>
    
    
      <category term="確率論" scheme="http://ktrmnm.github.io/blog/tags/%E7%A2%BA%E7%8E%87%E8%AB%96/"/>
    
      <category term="最適輸送" scheme="http://ktrmnm.github.io/blog/tags/%E6%9C%80%E9%81%A9%E8%BC%B8%E9%80%81/"/>
    
  </entry>
  
  <entry>
    <title>Generic Chaining (2)</title>
    <link href="http://ktrmnm.github.io/blog/2016/03/25/20160325-generic-chaining-2/"/>
    <id>http://ktrmnm.github.io/blog/2016/03/25/20160325-generic-chaining-2/</id>
    <published>2016-03-25T11:07:49.000Z</published>
    <updated>2020-03-01T09:20:31.186Z</updated>
    
    <content type="html"><![CDATA[<h1 id="連鎖-Chaining"><a href="#連鎖-Chaining" class="headerlink" title="連鎖 (Chaining)"></a>連鎖 (Chaining)</h1><p><a href="http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/">前回</a>の続き。</p><p>このノートの落とし所としては次のようなものを想定している：</p><ul><li>確率過程の最大値をバウンドするためのchainingという技術がある</li><li>chainingで得られるバウンドが非最適な場合がある</li><li>generic chainingという技術を使うとそのギャップが埋まる</li></ul><p>でも今回は、chainingについて書いたら力つきて終わりそうだ。</p><h1 id="距離エントロピー"><a href="#距離エントロピー" class="headerlink" title="距離エントロピー"></a>距離エントロピー</h1><p>$(T, d)$ を擬距離空間とする。$d$ で $T$ の大きさをはかり、それが $T$ 上の確率過程の最大値に与える影響が知りたいのだった。</p><p>大きさのはかり方としてここで想定しているのは、</p><ul><li>半径 $\epsilon$ の球が最低いくつあれば $T$ を覆うことができるか ($\epsilon$-netの最小数)</li><li>半径 $\epsilon$ の球を最大いくつ $T$ の中に押し込めるか ($\epsilon$-packingの最大数)</li></ul><p>といったもので、前者を<strong>被覆数</strong> (covering number)、後者を<strong>パッキング数</strong> (packing number)という。</p><a id="more"></a><p>ちゃんと定義を書く。</p><p>$(T, d)$ の$\epsilon$-被覆数 $N(T,d,\epsilon)$ とは、$t_1, \ldots, t_n \in T$ が存在して、$T \subset \bigcup_{i=1}^n B(t_i, \epsilon)$となるような最小の $n$ のこととする。ただし、$B(t, \epsilon)$は$t$を中心とする$\epsilon$-球である。</p><p>$(T, d)$ の$\epsilon$-パッキング数 $D(T,d,\epsilon)$ とは、$t_1, \ldots, t_n \in T$ が存在して、各$i \neq j$ について$d(t_i, t_j) &gt; \epsilon$ となるような最大の $n$ のこととする。</p><p>実は、覆うのも詰めるのもオーダーの上では違いがなくて、<br>$$<br>N(T, d, \epsilon) \leq D(T, d, \epsilon) \leq N(T, d, \epsilon/2)<br>$$<br>が成り立つ。これからの議論では定数倍の違いは気にしないので、被覆数に関して成り立つことはパッキング数でも成り立つし、逆も言える。必要に応じて便利な方に取り替えることができる。<br>（注）上の不等式の理由：<br>最大の$\epsilon$-packingは$\epsilon$-netにもなっていなければならないので左の不等式が成り立つ。<br>右については、$\epsilon/2$-netをひとつ固定すると、それぞれの球のなかには互いに$\epsilon$より離れた点を$1$点以上含むことができない。よって別の$\epsilon$-packingがあるとすれば、最大でもそれぞれの球にひとつずつ収まることしかできない。</p><p>なおこの界隈では、これらの対数をとった$\log N(T, d, \epsilon)$とか$\log D(T, d, \epsilon)$といった量をmetric entropyと呼ぶことがある。</p><h1 id="Dudley積分"><a href="#Dudley積分" class="headerlink" title="Dudley積分"></a>Dudley積分</h1><p>$T$ 上の確率過程 $X_t$ が $d$ についてのsub-Gaussian processであるとは、増分$X_t - X_s$がパラメータ$d(s,t)$のsub-Gaussianであることをいう:<br>$$<br>\mathbb{E} e^{\lambda(X_t - X_s)} \leq e^{\lambda^2 d(s,t)^2 /2}.<br>$$</p><p>結論からいうと、sub-Gaussian processの最大値について次のようなことが言える。(<a href="https://en.wikipedia.org/wiki/Dudley%27s_theorem" target="_blank" rel="noopener">Dudleyの定理</a>)</p><p><strong>定理</strong><br><em>$(T,d)$は擬距離空間で、$X_t$は$d$についてのsub-Gaussian processであるとする。<br>次ような積分が存在したとする:</em><br>$$<br>\int_0^\infty \sqrt{\log N(T,d,\epsilon)} \dd \epsilon &lt; \infty.<br>\tag{1}<br>$$<br><em>このとき、</em><br>$$<br>\mathbb{E}\sup_{t \in T} |X_t| \leq \mathbb{E}|X_{t_0}| + 4\sqrt{2} \int_0^{\mathrm{diam}T/2} \sqrt{\log 2 N(T, d, \epsilon)} \dd \epsilon<br>\tag{2}<br>$$<br><em>が成り立つ。ただし$t_0 \in T$は任意の点である。また、</em><br>$$<br>\mathbb{E}\sup_{t \in T: d(s,t)\leq \delta} |X_t - X_s| \leq (16\sqrt{2} + 2) \int_0^{\delta} \sqrt{\log 2 N(T, d, \epsilon)} \dd \epsilon<br>\tag{3}<br>$$<br><em>が成り立つ。</em></p><p>これらを示す技術がchainingと呼ばれているもので、そのため不等式自体もchaining boundとか呼ばれたりする。(2)と(3)の違いは、(3)の方はパスの一様連続性の度合い<br>$$<br>\sup_{t \in T: d(s,t)\leq \delta} |X_t - X_s|<br>$$<br>を$\delta$の関数として評価しているということだ。</p><p>これは個人的体験なのだが、機械学習を勉強していたつもりが上のような積分に初めて遭遇したときは心底ぎょっとした。なんじゃこりゃ感がある。カバリングナンバーを$\epsilon$で積分するって一体何事？と悩まざるを得ない。</p><p>なんじゃこりゃ感の正体だが、<strong>有限個のmax評価を次々に連鎖</strong> (chaining) したらこうなったのだ、と言える。</p><p><a href="http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/">前回</a>も述べたが、代表点として有限$\epsilon$-netをひとつ固定したとき、それらの上での $\max |X_t|$ の期待値は $\sqrt{\log 2N(T, d, \epsilon)}$ に比例する量で押さえられる。ここでのアイデアは、$\epsilon$をどんどん細かくして代表点を増やしていけば、最終的には$T$全体でのsupをカバーできるというものだ。そこで細かくする方法に少々工夫があって、その最中の評価を足しこんでいったものが(1)(2)(3)のような積分ということになる。</p><p>連鎖っぽさを具体的に感じるために、(2)の方を大雑把に示そうと思う。</p><h2 id="Chainingによる証明"><a href="#Chainingによる証明" class="headerlink" title="Chainingによる証明"></a>Chainingによる証明</h2><h3 id="1-前置き"><a href="#1-前置き" class="headerlink" title="1. 前置き"></a>1. 前置き</h3><p>$\mathrm{diam}T = 0$ または (1) の積分が $+\infty$ のときは無意味なので、$\mathrm{diam}T &lt; \infty$ とする。</p><p>距離$d$および$X_t$を等倍にスケールして、$\mathrm{diam}T &lt; 1$としても問題が生じないのでそうする。</p><p>また、とくに $T$ は全有界だが、$T$ 全体ではなく、稠密な加算集合 $T_0$ の上で (2) を示すことにする（下の可測性の補足も参照）。そのためには、任意の有限集合 $S \subset T$で (2) を示せばよい。そうすれば、$S_n \uparrow T_0$ の極限をとれば単調収束定理より $T_0$ でも成り立つ。</p><h3 id="2-Chainの構成"><a href="#2-Chainの構成" class="headerlink" title="2. Chainの構成"></a>2. Chainの構成</h3><p>$S$ を固定する。$k_1$ を十分大きくとって、$S$の2点どうしの距離で最も近いところより長さ $2^{-k_1}$ が短くなるようにとれば、$B(t, 2^{-k_1})$ は $S$ の点を高々1つまでしか含まない。<br>代表点の集合 $T_k$ を次のようにつくる。</p><ul><li>$T_{k_1} = S$</li><li>$1 \leq k \leq k_1$ に対して、$T_k$ を最小$2^{-k}$-netとする</li><li>$T_0 = \{ t_0 \}$</li></ul><p>絵を描いてみた。</p><img src="/blog/2016/03/25/20160325-generic-chaining-2/chaining_grid.png" title="Grid"><p>$\{ t_0 \}$ の1点集合からはじまって、半径を半分ずつに縮めたnetをとっていく。$k$番目のレイヤーには$N(T, d, 2^{-k})$個の点があって、最後の$k_1$番目のレイヤーだけはそれぞれのグリッドに$S$の点が1個以下収まっている。<br>絵心がないので「四角く」描いているけど、$T$ は有限次元でなくてもいいし、$B(t, \epsilon)$ たちはdisjointでもない。</p><p>次に、各 $s \in S$ に対して、$T_k$ への射影 $\pi_k(s)$ をひとつ定める。<br>基本的には、ひとつ上の階層の代表点のうち最も近いものに寄せていく。つまり、ある $t_k \in T_k$に対して $s \in B(t_k, 2^{-k})$ であれば、$\pi_k(s) = t_k$ と定める。$T_k$ は $2^{-k}$-netになっているはずだから、寄せるべき$T_k$の点は1つ以上は存在するが、もし2つ以上該当する場合は適当に一方を選ぶ。<br>ただし、$\pi_k(s) = \pi_k(s^\prime)$ ならば、$\pi_{k-1}(s) = \pi_{k-1}(s^\prime)$ となるようにする。</p><p>$\pi_k(s)$ の行き先をすべて図示してみると、下のようにツリー状になる。</p><img src="/blog/2016/03/25/20160325-generic-chaining-2/chaining.png" title="Chaining"><p>$s \in S = T_{k_1}$から出発して上に登っていく。2つの $s \neq s^\prime$　について、$\pi_k(s) = \pi_k(s^\prime)$ になるというのはそこでチェインが「合流」するということだが、そこから先は終点の $t_0$ に至るまでずっと同じチェインの上に乗っている。</p><p><del>今後も個人的に使いそうなので図を描いてみたが、大変だった……</del></p><h3 id="3-最大値評価"><a href="#3-最大値評価" class="headerlink" title="3. 最大値評価"></a>3. 最大値評価</h3><p>上の図で、チェインの作り方より、<br>$$<br>d(\pi_k(s), \pi_{k-1}(s)) \leq 2^{-(k-1)}<br>$$<br>である。$X_t$はsub-Gaussianだったので、これは<br>$$<br>\left[<br>\mathbb{E}(X(\pi_k(s)) - X(\pi_{k-1}(s)))^2<br>\right]^{1/2} \leq d(\pi_k(s), \pi_{k-1}(s)) \leq 2^{-(k-1)}<br>\tag{4}<br>$$<br>を意味する ($X(t) = X_t$)。</p><p>一方、ツリー状に配置したおかげで、第$k$層と$k-1$層を結ぶ青い線は高々 $|T_k| = N(T, d, 2^{-k})$ 種類しかない。したがって、最大不等式より</p><p>$$<br>\mathbb{E}\max_{s \in S} |X(\pi_k(s)) - X(\pi_{k-1}(s))|　\leq 2^{-(k-1)} \sqrt{2 \log 2 N(T, d, 2^{-k})}<br>$$<br>となる。</p><p>よって、<br>$$<br>\begin{align}<br>\mathbb{E}\max_{s \in S} |X_t - X_{t_0}|<br>&amp; \leq \sum_{k=1}^{k_1} \mathbb{E}\max_{s \in S} |X(\pi_k(s)) - X(\pi_{k-1}(s))| \\<br>&amp; \leq \sum_{k=1}^{\infty} 4 \times 2^{-k-1} \sqrt{2 \log 2 N(T, d, 2^{-k})} \\<br>&amp; \leq \sum_{k=1}^{\infty} 4 \int_{2^{-k-1}}^{2^{-k}} \sqrt{2 \log 2 N(T, d, \epsilon)} \dd \epsilon \\<br>&amp; = 4 \int_{0}^{\mathrm{diam}T /2} \sqrt{2 \log 2 N(T, d, \epsilon)} \dd \epsilon.<br>\end{align}<br>$$</p><p>これで (2) が示された。</p><p>えっ。</p><p><strong>すげえ。</strong></p><p>要するに、増分のsub-Gaussian性（より一般にはOrliczノルムでのLipschitz性 [3]）から、(4) 式のように解像度を細かくしていくと分散が上手くコントロールされる。で、解像度の上げ方をツリー状にまとめ上げることで、各層で考えるべき候補の数を減らしている、というところがポイントである。</p><h3 id="空間が大きいと最大値が暴れる"><a href="#空間が大きいと最大値が暴れる" class="headerlink" title="空間が大きいと最大値が暴れる"></a>空間が大きいと最大値が暴れる</h3><p>上で描いた図では2次元なので、半径 $\epsilon$ を $1/2$ にしたときに $N(T, d, \epsilon)$ は $4$ 倍程度にしかならない。</p><p>しかし、一般に $T$ が無限次元だと、カバリングナンバーはもっと急速に増える可能性がある。そして、あまりに爆発的に増えすぎるとエントロピーの積分が収束しないため、最大値がバウンドできないことになる。これが、添字空間が大きすぎると最大値が発散することのイメージである。</p><h1 id="Chainingだと物足りないケース"><a href="#Chainingだと物足りないケース" class="headerlink" title="Chainingだと物足りないケース"></a>Chainingだと物足りないケース</h1><p>Chainingのおかげで、要素数無限大でも最大値がバウンドできるようになってハッピーだ。</p><p>次に疑問になってくるのは、エントロピーで得られる (1) のようなバウンドが一体どれくらいタイトなのか、ということだ。<br>実は、実用上使いそうであるにもかかわらず、あまりタイトではない例が知られている。具体例を書こうと思ったが、スペース上の都合で次回にまわす。</p><p>そこで<strong>generic chaining</strong>である。</p><p>とくに、$X_t$ が ガウス過程の場合は<br>$$<br>\frac{1}{C}\gamma_2(T, d) \leq \mathbb{E}\sup_{t \in T} X_t \leq C \gamma_2(T, d)<br>$$<br>のように<strong>下界もgeneric chainingで書ける</strong>ということがわかっていて (majorizing measure theorem)、正真正銘タイトなバウンドである。</p><h2 id="補足：GC集合"><a href="#補足：GC集合" class="headerlink" title="補足：GC集合"></a>補足：GC集合</h2><p>Dudley積分の偉いところは、supの期待値の有界性だけでなくて、標本のごと連続度も表現してくれていることだ。<br>どういうことかというと、確率1で<br>$$<br>\sup_{s,t \in T} \frac{|X_t - X_s|}{\int_0^{d(s,t)} \sqrt{2 \log 2 N(T, d, \epsilon)} \dd \epsilon} &lt; \infty<br>$$<br>が成り立つ（[1] Theorem 2.3.8, [2] Theorem 2.3.6)。ただし、こっちを示す方がだいぶしんどい。</p><p>ガウス過程に関して、$\sup_t X_t$ が有界になるような $T$ をGB集合、さらに$d$-一様連続になるような $T$ をGC集合という[2]。つまりDudley積分はGC集合であるための十分条件を与えてくれる。</p><h2 id="補足2：Donsker性の判定"><a href="#補足2：Donsker性の判定" class="headerlink" title="補足2：Donsker性の判定"></a>補足2：Donsker性の判定</h2><p>さらにさらに、経験過程 $\sqrt{n}(P_n - P)$ が標本連続なガウス過程に法則収束してくれるか否か (一様中心極限定理！) というのは経験過程論における大問題である[2]。もし収束するなら、その添字集合は<strong>Donskerクラス</strong>であるという。<br>これを判定するにはどうすればいいかというと、結局のところ添字集合の大きさが問題になる。そもそも収束先のガウス過程にとってGC集合になっていないといけないのだから、Dudley積分のような、「標本連続性をコントロールする何か」を見てDonskerクラスかどうか判定できるんじゃないかという気がする。それはだいたい正しいのだが、経験過程の色々なことを一言で説明するのは「無理！」という感じなので[1]や[2]を参照。</p><h2 id="めんどくさい補足：可測性"><a href="#めんどくさい補足：可測性" class="headerlink" title="めんどくさい補足：可測性"></a>めんどくさい補足：可測性</h2><p>可測性の話を完全に無視した。これからも無視する。</p><p>どういうことかというと、可測関数の非可算個のsupは可測とは限らないのだから、本当は$\sup_t X_t$は確率変数とは限らないのだ。しかし、(1)の積分が存在するケースでは$T$はそもそも全有界で、$X_t$にはa.s.で一様連続なパスが出てくるバージョンが存在するので、supも可算集合の上で考えればよいから実質的に問題にならない[1]。あるいは、[3]や[4]ではsupの解釈そのものを、はじめから $\sup\{ \mathbb{E}\sup_{t \in F} |X_t|: F は有限集合\}$ と考えているようだ。</p><p>これに限らず、興味ある対象が非可算supなせいで経験過程関係の本 (とくに[2]！) には可測性の話がうじゃうじゃ出てくる。私の近所では「初見殺しだ」ということで話題だ。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Giné and Nickl. Mathematical Foundations of Infinite-Dimensional Statistical Models, Cambridge University Press, 2015.<br>[2] Dudley. Uniform Central Limit Theorems (2nd edition), Cambrige University Press, 2014.<br>[3] Ledoux and Talagrand. Probability in Banach Spaces, Springer, 1991.<br>[4] Talagrand. Upper and Lower Bounds for Stochastic Processes, Springer, 2014.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;連鎖-Chaining&quot;&gt;&lt;a href=&quot;#連鎖-Chaining&quot; class=&quot;headerlink&quot; title=&quot;連鎖 (Chaining)&quot;&gt;&lt;/a&gt;連鎖 (Chaining)&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/&quot;&gt;前回&lt;/a&gt;の続き。&lt;/p&gt;
&lt;p&gt;このノートの落とし所としては次のようなものを想定している：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;確率過程の最大値をバウンドするためのchainingという技術がある&lt;/li&gt;
&lt;li&gt;chainingで得られるバウンドが非最適な場合がある&lt;/li&gt;
&lt;li&gt;generic chainingという技術を使うとそのギャップが埋まる&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;でも今回は、chainingについて書いたら力つきて終わりそうだ。&lt;/p&gt;
&lt;h1 id=&quot;距離エントロピー&quot;&gt;&lt;a href=&quot;#距離エントロピー&quot; class=&quot;headerlink&quot; title=&quot;距離エントロピー&quot;&gt;&lt;/a&gt;距離エントロピー&lt;/h1&gt;&lt;p&gt;$(T, d)$ を擬距離空間とする。$d$ で $T$ の大きさをはかり、それが $T$ 上の確率過程の最大値に与える影響が知りたいのだった。&lt;/p&gt;
&lt;p&gt;大きさのはかり方としてここで想定しているのは、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;半径 $\epsilon$ の球が最低いくつあれば $T$ を覆うことができるか ($\epsilon$-netの最小数)&lt;/li&gt;
&lt;li&gt;半径 $\epsilon$ の球を最大いくつ $T$ の中に押し込めるか ($\epsilon$-packingの最大数)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;といったもので、前者を&lt;strong&gt;被覆数&lt;/strong&gt; (covering number)、後者を&lt;strong&gt;パッキング数&lt;/strong&gt; (packing number)という。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/3" scheme="http://ktrmnm.github.io/blog/categories/2016-3/"/>
    
    
      <category term="学習理論" scheme="http://ktrmnm.github.io/blog/tags/%E5%AD%A6%E7%BF%92%E7%90%86%E8%AB%96/"/>
    
      <category term="経験過程論" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%8C%E9%A8%93%E9%81%8E%E7%A8%8B%E8%AB%96/"/>
    
  </entry>
  
  <entry>
    <title>Generic Chaining (1)</title>
    <link href="http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/"/>
    <id>http://ktrmnm.github.io/blog/2016/03/23/20160322-generic-chaining-1/</id>
    <published>2016-03-23T11:39:00.000Z</published>
    <updated>2020-03-01T09:20:31.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>学習理論や機械学習周辺を勉強していると、しばしば「確率過程の最大値」というものが出てくる。確率過程といっても色々あるものの、主に興味があるのは<a href="https://en.wikipedia.org/wiki/Empirical_process" target="_blank" rel="noopener">経験過程</a>とその極限として出てくる<a href="https://en.wikipedia.org/wiki/Gaussian_process" target="_blank" rel="noopener">ガウス過程</a>の2つだ。これらは、「リスクの挙動が知りたい」「M推定量の一致性が知りたい」といった統計的なモチベーションに関係してくる。</p><p>このノートでは、確率過程の最大値の測り方についての、比較的つっこんだ内容を数回に分けて書こうと思う。</p><h2 id="ノートの趣旨"><a href="#ノートの趣旨" class="headerlink" title="ノートの趣旨"></a>ノートの趣旨</h2><p><strong>Generic chaining</strong>と呼ばれるものに関して知られている結果を、証明抜きで並べようと思う。</p><h2 id="Generic-chainingとは何をするためのものか"><a href="#Generic-chainingとは何をするためのものか" class="headerlink" title="Generic chainingとは何をするためのものか"></a>Generic chainingとは何をするためのものか</h2><p>経験過程やガウス過程の最大値は、添え字の空間が大きすぎると暴れる。</p><p>平均0の確率過程 $(X_t)$ があるとき、添え字の空間には $(X_t)$ の相関構造をもとに擬距離が入る。ところがその距離の意味で添え字の空間が大きすぎると、$\sup_t |X_t|$ は発散してしまう。大きさの測り方はいろいろあるのだが、基本的には全有界性のようなものがコントロールされていることが望ましい。例えば、カバリングナンバー ($\epsilon$ を固定したときの $\epsilon$-netの要素数の最小値) が大きすぎないことが条件になる。</p><p>逆に、「添字空間の大きさを測る尺度」によって確率過程の最大値をタイトに評価できることが知られている。</p><p>そこでようやく表題の概念が出てくる。<br>ワンセンテンスで言えば、Generic chainingというのは、<strong>確率過程の最大値を添字空間の大きさを使って評価するやり方のなかで、とりわけ高級なもの</strong>である。同目的のテクニックに連鎖 (chaining) という名前がついているものがまずあって、それをさらに一般化したものなのでこういう名前がついている。</p><p>結論の一部を先取りすると、距離の入った添字空間 $(T, d)$ の複雑さの尺度を、次のような量で測る：<br>$$<br>\gamma_2(T, d) := \inf \sup_{t \in T} \sum_{n=0}^\infty 2^{n/2} d(t, T_n)<br>$$<br>$T_n$ というのは $T$ の「代表点の集合」で、基本的には $n=0,1,\ldots$ とともに要素数が増えていく。だんだん解像度を上げていく感じだ。$T_n$ 要素数の増え方にはある程度制限がかかっていて、$\inf$ はそのような $T_n$ の全体にわたってとる。<br>このように定義した $\gamma_2$ という謎の量が、なぜかガウス過程のsupの性質をとてもよく捉えている。</p><p>これがしかしどの程度重要な概念かというと、言ってしまえばマニアックな知識だ。機械学習の論文を読む人間の95%にとって必要にならない程度だと思う。それでも、例えば昨年 (2015年) のNIPSにもそれ自体をテーマにした論文が通っていたりして、やっている人はやっている。つまり、この知識が必要になる残りの5%とは、学習理論をやっている人間のことである。</p><a id="more"></a><h2 id="最尤推定からの導入"><a href="#最尤推定からの導入" class="headerlink" title="最尤推定からの導入"></a>最尤推定からの導入</h2><p>ちょっと脱線して、どのような確率過程に興味があるのか、例を書いてみる。（ただし前後の話とは直接の関係がない。）</p><p>統計っぽい学問の中には、ものすごく大雑把ではあるが、次のような形で書ける問題がわりと多いはずだ：</p><ul><li>$X= (X_1, X_2, \ldots, X_n)$というデータが観測された。</li><li>実はデータ $X$ は、未知の確率分布 $P$ に独立同一分布でしたがう確率変数（の実現）であったらしい。</li><li>このとき、$P$ について何が言えるか？</li></ul><p>「$P$ について何か言う」という言い回しだとあまりに漠然としている。ひとつの具体的な形としては、「$P$ の期待値の形で書ける目的関数 (リスク関数) を最小化する最適化問題を解きたい」というのがある。</p><p>確率分布のパラメータ推定がいい例だ。<br>$\mathcal{P} = \{ P_\theta: \theta \in \Theta \}$という候補集合の中に $P$ が含まれているのだ、という仮説を立ててみる。パラメータの集合 $\Theta$ は有限次元の多様体だったり (正則パラメトリックモデル)、有限次元っぽいけど境界があったり所々尖っていて多様体だと見なせなかったり (特異モデル)、関数空間だったり (ノンパラメトリック) 色々だ。</p><p>問題は次のようになる：<br><em>真のパラメータ $\theta_0 \in \Theta$ が存在して、$X_{i} (i=1,\ldots, n)$ は $P = P_{\theta_0}$ にi.i.d.に従っているとする。$\theta_0$を当てよ。</em></p><p>「当てよ」というのは、推定量 $\hat{\theta}(X_1, \ldots, X_n)$ という名の関数を構成して $\theta_0$ にできる限り近づけ、ということだ。そして、「できる限り近づけ」というのは適当な擬距離を与えれば定義できる。尺度はなんでもいいのだが、説明の都合上、天下り的に<a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence" target="_blank" rel="noopener">KLダイバージェンス</a>を使うことにする。<br>$$<br>\rho(\theta_0, \hat{\theta}) = P \log \frac{p(x \mid \theta_0)}{p(x \mid \hat{\theta})}<br>= - P \log p(x \mid \hat{\theta}) + P \log p(x \mid \theta_0)<br>$$<br>上の式で$P \log p(x \mid \theta_0)$ というのは $\theta_0$ にしか依らないから、$\hat{\theta}$ を動かして最適化しようという営みにはたぶん関係がないだろう。というわけで結局、次のような問題を考えることになる。</p><p><em>次のリスク関数を最小にする $\hat{\theta}$を選べ：</em><br>$$<br>R(\hat{\theta}) = -P \log p(x \mid \hat{\theta}) = \int -\log p(x \mid \hat{\theta}) \dd P(x).<br>$$</p><p>しかし、これが $R(\theta)$ という関数の単なる最適化問題にならないのが統計学の困ったところだ。</p><p>なぜなら、そもそもの目的は $P$ を知ることであってそれは未知なのだから、それによって定義されるリスクも未知である。ためしに作ってみた推定量がリスクをどの程度小さくしてくれるかは永久に観測できない。<br>一方、真の期待値 $P$ の代わりに得られるのは経験期待値 $P_n$ である。経験リスク関数<br>$$<br>R_n(\theta) = - \frac{1}{n} \sum_{i=1}^n \log p(X_i \mid \theta)<br>$$<br>が、サンプルサイズ $n$ が大きくなるにつれて真の $R$ に収束したとする。このとき、$R_n$を最小化してつくった $\hat{\theta}$ は漸近的に真の $\theta_0$ に収束してくれる (一致性)。$n$ が有限でも十分大きければまあそこそこ信用ができるだろう。これが最尤推定量である。もう少し一般的なくくりでは、M推定量とか経験リスク最小化 (ERM) とか呼ばれる。</p><p>$R_n$ が $R$ に収束すると嬉しいと述べたが、もう少し正確には $\Theta$ 上で一様収束すると嬉しい。$\theta$を固定すれば、<a href="https://ja.wikipedia.org/wiki/大数の法則" target="_blank" rel="noopener">大数の法則</a>があるので各点収束はするのだが、それでは不十分だ。本当は$\theta$を動かして、最小値をとるところでの挙動を考えたい。だから、興味があるのは<br>$$<br>\sup _{\theta \in \Theta} |P_n \log p(\cdot \mid \theta) - P \log p(\cdot \mid \theta) |<br>$$<br>という量になる。これは「$\Theta$ 上の確率過程の最大値」である。さらに、もっと一般には $\Theta$ が関数空間だったりするので、与えられた関数の集合 $\mathcal{F}$ に対して<br>$$<br>\sup_{f \in \mathcal{F}} |P_n f - Pf|<br>$$<br>の挙動が手っ取り早くわかる理論が欲しい。</p><p>ここで出てくる $P_n - P$ という「関数空間を添え字にもつ確率過程」を経験過程と呼ぶ。</p><p>さて、$n \to \infty$ の極限で、スケールした経験過程 $\sqrt{n} (P_n - P)$ はガウス過程に法則収束することがある。中心極限定理の無限次元版みたいな感じだ。だからガウス過程というのは、経験過程を使って書けるいくつかの現象（最尤推定、M推定、 LASSO）たちの、ある意味で極限に居座っている存在なのであって、ガウス過程について調べることがそれらの漸近挙動を調べることにつながったりする。</p><h1 id="有限個のsub-Gaussianの最大値"><a href="#有限個のsub-Gaussianの最大値" class="headerlink" title="有限個のsub-Gaussianの最大値"></a>有限個のsub-Gaussianの最大値</h1><p>最大値の話に戻る。</p><p>$(X_t)$ で $t \in T$ 上の確率過程を表すとする。$(T, d)$ と書いたら $d$ は擬距離ということにする。<br>$d$ で測ったときの $T$ の複雑さが $\sup_t |X_t|$ の挙動にどのような影響を与えるのか、というのが興味の対象である。しかし、何事も一番つまらない例から考えようと思う。</p><p><strong>$T$ が有限集合だったら簡単だ。</strong></p><p>$T = \{ 1, 2, \ldots, N \}$ としてみる。<br>この場合は確率過程といっても有限個の確率変数のあつまりで、supはいつもmaxのことだ。</p><p>例えば、$|X_t|$の分布関数の上界が与えられていたとする。<br>$$<br>\Pr (|X_t| \leq a) \leq F(a)<br>$$<br>$X_t$ たちの相関構造は完全に無視しても、union boundというものがあるので、次のようなことは言える。<br>$$<br>\Pr(\max_t |X_t| \leq a) \leq \sum_{t=1}^N F(a) = NF(a)<br>$$<br>楽勝だ。<br>期待値に関しても、各$t$について$\mathbb{E}|X_t| \leq B$だとすれば、非負のもののmaxよりは和のほうが小さくないので<br>$$<br>\mathbb{E} \max_t |X_t| \leq N B<br>\tag{1}<br>$$<br>楽勝だ。</p><p>いや良くないです。</p><p>これではさすがにつまらなすぎるので、$T$ が有限個の範囲内で、もう少し精密なことを考えてみる。<br>$X_t$ たちの相関を考えないのは上と同じではあるが、$X_t$ は<a href="https://en.wikipedia.org/wiki/Sub-Gaussian_random_variable" target="_blank" rel="noopener">sub-Gaussian</a>、つまりモーメント母関数が次の不等式を満たすもの<br>$$<br>\mathbb{E}e^{\lambda X_t} \leq \exp\left(\frac{\lambda^2 \sigma_t^2}{2}\right)<br>$$<br>であるとしてみる。<br>$X_t$ が $\sigma_t^2$ より小さい分散をもつ正規分布だったり、有界だったりすれば、sub-Gaussianである。<br>あるいは、<br>$$<br>\Pr (|X_t| &gt; a) \leq C \exp \left( -\frac{a^2}{2\sigma_t^2} \right)<br>$$<br>のような裾確率をもっていればsub-Gaussianである。要はGaussianより裾が軽いという意味だ。</p><p>すると、有限個のsub-Gaussianの最大値について、次のようなことが言える。</p><p><strong> 定理 (sub-Gaussianの最大不等式) </strong></p><hr><p><em>$X_t$ ($t = 1, \ldots, N$) はそれぞれパラメータ$\sigma^2_t$をもつsub-Gaussian確率変数であるとする。このとき、<br>$$<br>\mathbb{E}\max_t X_t \leq \sqrt{2 \log N} \max_t \sigma_t^2<br>\tag{2}<br>$$<br>および<br>$$<br>\mathbb{E}\max_t |X_t| \leq \sqrt{2 \log 2N} \max_t \sigma_t^2<br>\tag{3}<br>$$<br>が成り立つ。</em></p><p>単純な (1) が $T$ の要素数 $N$ に比例したバウンドだったのに対して、こちらは $\sqrt{\log N}$ というオーダーなのでまだ地球に優しい。<br>証明はわりと簡単なのだが省略する。主張の形は[1]のプレプリント版のLemma 2.3.4 を参考にした。</p><h1 id="無限個だと結局困る"><a href="#無限個だと結局困る" class="headerlink" title="無限個だと結局困る"></a>無限個だと結局困る</h1><p>有限個だったらほぼこれでいいのだが、(1) にしろ (2) にしろ (3) にしろ、結局 $N = \infty$ だと意味のないバウンドになってしまう。<br>この先に行くためには、$X_t$ どうしの相関を考慮にいれる必要がある。</p><p>特に、$T$ に距離が定義されていて、近いところにいる $X_t$ たちはほぼ近い値をとるのであれば、そいつら同士を比べてもあまり意味がない。互いに距離 $\epsilon$ 以上離れた $t$ をピックアップしてその中での最大値を考えればいい気がする。というわけで、距離 $d$ でみた $T$ の大きさを考えるモチベーションがようやく生じてくるのだが、記事が長くなりそうなのでこの辺で区切る。</p><h2 id="※まとめ作成の動機"><a href="#※まとめ作成の動機" class="headerlink" title="※まとめ作成の動機"></a>※まとめ作成の動機</h2><p>個人的には、generic chainingそのものに興味があるというわけではないけれど、「モデルの大きさの測り方」について、ちょっと執拗なくらいに理解してしまいたいという気持ちはある。「モデルが複雑すぎると過学習するよね」「だからAICなどでモデル選択するんだ」というストーリーは今や誰でも馴染み深い。ところが、ではモデルの複雑さはどう定義されるのか、過学習って一体何なのか、<strong>いやそもそも学習って何や</strong>、ということを突き詰めてみると、本質的なところは案外わからない。少なくとも自分にはまだ答えられる気がしない。仮に答えたとしても、隣の席に座っているデータサイエンティスト同士で話が食い違いそうだ。p値のことだって誰も知らない。<br>一方で冷静な事実として、推定量の候補があまりに多すぎると経験過程の最大値が暴れてしまう。だから、一致性が理論的に (あくまで理論的に) 破綻してしまうモデルの大きさというのがあって、その境目を超えた大きさで最尤推定してしまったものは文句なく過学習と言えそうだ。</p><p>（嘘です。モデル選択についてはもっと統計っぽい深い話はあるはずだし、過学習とは何かについても、こんな数学みたいな水準の話ではなく、統計学や学習理論の枠内で決着がつく気がする。事件は会議室で起きているんじゃない。現場で起きているんだ。）</p><p>とにかく、モノの複雑さを測るための既存の方法を整理しておきたいということである。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Giné and Nickl. Mathematical Foundations of Infinite-Dimensional Statistical Models, Cambridge University Press, 2015.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;学習理論や機械学習周辺を勉強していると、しばしば「確率過程の最大値」というものが出てくる。確率過程といっても色々あるものの、主に興味があるのは&lt;a href=&quot;https://en.wikipedia.org/wiki/Empirical_process&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;経験過程&lt;/a&gt;とその極限として出てくる&lt;a href=&quot;https://en.wikipedia.org/wiki/Gaussian_process&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ガウス過程&lt;/a&gt;の2つだ。これらは、「リスクの挙動が知りたい」「M推定量の一致性が知りたい」といった統計的なモチベーションに関係してくる。&lt;/p&gt;
&lt;p&gt;このノートでは、確率過程の最大値の測り方についての、比較的つっこんだ内容を数回に分けて書こうと思う。&lt;/p&gt;
&lt;h2 id=&quot;ノートの趣旨&quot;&gt;&lt;a href=&quot;#ノートの趣旨&quot; class=&quot;headerlink&quot; title=&quot;ノートの趣旨&quot;&gt;&lt;/a&gt;ノートの趣旨&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Generic chaining&lt;/strong&gt;と呼ばれるものに関して知られている結果を、証明抜きで並べようと思う。&lt;/p&gt;
&lt;h2 id=&quot;Generic-chainingとは何をするためのものか&quot;&gt;&lt;a href=&quot;#Generic-chainingとは何をするためのものか&quot; class=&quot;headerlink&quot; title=&quot;Generic chainingとは何をするためのものか&quot;&gt;&lt;/a&gt;Generic chainingとは何をするためのものか&lt;/h2&gt;&lt;p&gt;経験過程やガウス過程の最大値は、添え字の空間が大きすぎると暴れる。&lt;/p&gt;
&lt;p&gt;平均0の確率過程 $(X_t)$ があるとき、添え字の空間には $(X_t)$ の相関構造をもとに擬距離が入る。ところがその距離の意味で添え字の空間が大きすぎると、$\sup_t |X_t|$ は発散してしまう。大きさの測り方はいろいろあるのだが、基本的には全有界性のようなものがコントロールされていることが望ましい。例えば、カバリングナンバー ($\epsilon$ を固定したときの $\epsilon$-netの要素数の最小値) が大きすぎないことが条件になる。&lt;/p&gt;
&lt;p&gt;逆に、「添字空間の大きさを測る尺度」によって確率過程の最大値をタイトに評価できることが知られている。&lt;/p&gt;
&lt;p&gt;そこでようやく表題の概念が出てくる。&lt;br&gt;ワンセンテンスで言えば、Generic chainingというのは、&lt;strong&gt;確率過程の最大値を添字空間の大きさを使って評価するやり方のなかで、とりわけ高級なもの&lt;/strong&gt;である。同目的のテクニックに連鎖 (chaining) という名前がついているものがまずあって、それをさらに一般化したものなのでこういう名前がついている。&lt;/p&gt;
&lt;p&gt;結論の一部を先取りすると、距離の入った添字空間 $(T, d)$ の複雑さの尺度を、次のような量で測る：&lt;br&gt;$$&lt;br&gt;\gamma_2(T, d) := \inf \sup_{t \in T} \sum_{n=0}^\infty 2^{n/2} d(t, T_n)&lt;br&gt;$$&lt;br&gt;$T_n$ というのは $T$ の「代表点の集合」で、基本的には $n=0,1,\ldots$ とともに要素数が増えていく。だんだん解像度を上げていく感じだ。$T_n$ 要素数の増え方にはある程度制限がかかっていて、$\inf$ はそのような $T_n$ の全体にわたってとる。&lt;br&gt;このように定義した $\gamma_2$ という謎の量が、なぜかガウス過程のsupの性質をとてもよく捉えている。&lt;/p&gt;
&lt;p&gt;これがしかしどの程度重要な概念かというと、言ってしまえばマニアックな知識だ。機械学習の論文を読む人間の95%にとって必要にならない程度だと思う。それでも、例えば昨年 (2015年) のNIPSにもそれ自体をテーマにした論文が通っていたりして、やっている人はやっている。つまり、この知識が必要になる残りの5%とは、学習理論をやっている人間のことである。&lt;/p&gt;
    
    </summary>
    
      <category term="2016/3" scheme="http://ktrmnm.github.io/blog/categories/2016-3/"/>
    
    
      <category term="学習理論" scheme="http://ktrmnm.github.io/blog/tags/%E5%AD%A6%E7%BF%92%E7%90%86%E8%AB%96/"/>
    
      <category term="経験過程論" scheme="http://ktrmnm.github.io/blog/tags/%E7%B5%8C%E9%A8%93%E9%81%8E%E7%A8%8B%E8%AB%96/"/>
    
  </entry>
  
  <entry>
    <title>MathJax数式についてのメモ</title>
    <link href="http://ktrmnm.github.io/blog/2016/03/22/math-test/"/>
    <id>http://ktrmnm.github.io/blog/2016/03/22/math-test/</id>
    <published>2016-03-21T18:11:22.000Z</published>
    <updated>2020-03-01T09:20:31.246Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p><a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a>でブログを生成した。MathJaxのプラグインもあるため、LaTeXの数式を労力なく書けそうだからである。</p><p>とはいえ、MathJaxでものを書くのは初めてだ。ここではHexoプラグインの導入方法と、MathJaxの記述方法についてまとめておく。（2016/3/22現在）</p><h2 id="プラグイン導入"><a href="#プラグイン導入" class="headerlink" title="プラグイン導入"></a>プラグイン導入</h2><p><a href="https://github.com/akfish/hexo-math" target="_blank" rel="noopener">hexo-math</a>プラグインを利用することにした。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install hexo-math --save</span><br></pre></td></tr></table></figure></p><p>でインストールし、Hexoプロジェクトの設定ファイル <code>_config.yml</code> に以下を記述する:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">math:</span><br><span class="line">  engine: &apos;mathjax&apos;</span><br><span class="line">  mathjax:</span><br><span class="line">    src: http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML</span><br><span class="line">    config:</span><br><span class="line">      tex2jax:</span><br><span class="line">        inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&quot;\\(&quot;,&quot;\\)&quot;] ]</span><br><span class="line">        displayMath: [ [&apos;$$&apos;,&apos;$$&apos;], [&quot;\\[&quot;,&quot;\\]&quot;] ]</span><br></pre></td></tr></table></figure></p><h2 id="基本的な記述"><a href="#基本的な記述" class="headerlink" title="基本的な記述"></a>基本的な記述</h2><p>行内数式はLaTeXと同様で <code>$ f(x) = x^2 $</code>のように書けばよい: $f(x)=x^2$.<br>別行立てで書くには <code>$$</code> で挟んで書く。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$</span><br><span class="line">\mathbb&#123;E&#125; \max_&#123;s,t\in S: d(s,t) \leq \delta&#125; |X(t)-X(s)| \leq (16 \sqrt&#123;2&#125; + 2)</span><br><span class="line">\int_0^\delta \sqrt&#123;\log 2N(T, d, \varepsilon)&#125; \mathrm&#123;d&#125;\varepsilon</span><br><span class="line">\tag&#123;999&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure></p><p>$$<br>\mathbb{E} \max_{s,t\in S: d(s,t) \leq \delta} |X(t)-X(s)| \leq (16 \sqrt{2} + 2)<br>\int_0^\delta \sqrt{\log 2N(T, d, \varepsilon)} \mathrm{d}\varepsilon<br>\tag{999}<br>$$</p><p>なるほどなあ。むしろ、何ができないのか試したくて<code>\mathbb{E}</code>などを試したのだが、普通に使えるようなのでありがたい。これで$\mathbb{R}$とか$\mathbb{Z}$なども使い放題である。その他に使えるLaTeXコマンドの一覧は<a href="http://mathjax.readthedocs.org/en/latest/tex.html" target="_blank" rel="noopener">MathJaxのドキュメント</a>に載っている。</p><h2 id="マクロ"><a href="#マクロ" class="headerlink" title="マクロ"></a>マクロ</h2><p>MathJaxではマクロも定義できるが、今回は必要に応じて次のように書けばよい。YAMLなせいか心持ちすっきりと書けている気がする。<br><figure class="highlight plain"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">math:</span><br><span class="line">  engine: &apos;mathjax&apos; # or &apos;katex&apos;</span><br><span class="line">  mathjax:</span><br><span class="line">    src: http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML</span><br><span class="line">    config:</span><br><span class="line">      tex2jax:</span><br><span class="line">        inlineMath: [ [&apos;$&apos;,&apos;$&apos;], [&quot;\\(&quot;,&quot;\\)&quot;] ]</span><br><span class="line">        displayMath: [ [&apos;$$&apos;,&apos;$$&apos;], [&quot;\\[&quot;,&quot;\\]&quot;] ]</span><br><span class="line">      TeX:</span><br><span class="line">        Macros:</span><br><span class="line">          dd: \mathrm&#123;d&#125;</span><br><span class="line">          RR: \mathbb&#123;R&#125;</span><br><span class="line">          argmax: \operatorname*&#123;argmax&#125;</span><br></pre></td></tr></table></figure><br>例えば上では<code>\argmax</code>を定義したので次のように書ける：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$$</span><br><span class="line">\argmax_&#123;t \in T&#125; f(t)</span><br><span class="line">$$</span><br></pre></td></tr></table></figure></p><p>$$<br>\argmax_{t \in T} f(t)<br>$$</p><h2 id="Hexo特有の記法"><a href="#Hexo特有の記法" class="headerlink" title="Hexo特有の記法"></a>Hexo特有の記法</h2><p>ところで、Hexoにはこれとは別に<a href="https://hexo.io/docs/tag-plugins.html" target="_blank" rel="noopener">Hexo記法</a>というものが存在し、次のように書くことで同様の結果が得られる。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;% math %&#125;</span><br><span class="line">\mathbb&#123;E&#125; \max_&#123;s,t\in S: d(s,t) \leq \delta&#125; |X(t)-X(s)| \leq (16 \sqrt&#123;2&#125; + 2)</span><br><span class="line">\int_0^\delta \sqrt&#123;\log 2N(T, d, \varepsilon)&#125; \mathrm&#123;d&#125;\varepsilon</span><br><span class="line">&#123;% endmath %&#125;</span><br></pre></td></tr></table></figure></p><span>$$\mathbb{E} \max_{s,t\in S: d(s,t) \leq \delta} |X(t)-X(s)| \leq (16 \sqrt{2} + 2)\int_0^\delta \sqrt{\log 2N(T, d, \varepsilon)} \mathrm{d}\varepsilon$$</span><!-- Has MathJax --><p>ただし、hexo-mathの現在の仕様では、mathブロックの中に単一の行しかないときはインライン数式、それ以外はディスプレイ数式として勝手に解釈される。個人的にはちょっと不便だなとも思う。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://hexo.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;
      
    
    </summary>
    
      <category term="2016/3" scheme="http://ktrmnm.github.io/blog/categories/2016-3/"/>
    
    
      <category term="数学" scheme="http://ktrmnm.github.io/blog/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="MathJax" scheme="http://ktrmnm.github.io/blog/tags/MathJax/"/>
    
  </entry>
  
</feed>
